"""
ç³»ç»Ÿé›†æˆæµ‹è¯• - åŸºäºç«å“åˆ†æçš„åŠŸèƒ½éªŒè¯
æµ‹è¯•æ‰€æœ‰åŸºäºOffermore.ccã€Hina.comã€Dayee.comä¼˜åŒ–çš„åŠŸèƒ½æ¨¡å—
"""

import pytest
import asyncio
import json
from datetime import datetime
from typing import Dict, List, Any

from app.services.intelligent_conversation_manager import intelligent_conversation_manager
from app.services.enhanced_capability_evaluator import EnhancedCapabilityEvaluator
from app.services.enhanced_iflytek_service import enhanced_iflytek_service

class TestCompetitorAnalysisIntegration:
    """ç«å“åˆ†æåŠŸèƒ½é›†æˆæµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰ç½®è®¾ç½®"""
        self.conversation_manager = intelligent_conversation_manager
        self.capability_evaluator = EnhancedCapabilityEvaluator()
        self.iflytek_service = enhanced_iflytek_service
        
        # æµ‹è¯•æ•°æ®
        self.test_session_id = "test_session_001"
        self.test_domain = "äººå·¥æ™ºèƒ½"
        self.test_position = "AIç®—æ³•å·¥ç¨‹å¸ˆ"
        
    @pytest.mark.asyncio
    async def test_offermore_style_features(self):
        """æµ‹è¯•Offermore.ccé£æ ¼åŠŸèƒ½ - å®æ—¶æ™ºèƒ½åŠ©æ‰‹"""
        print("ğŸ” æµ‹è¯•Offermore.ccé£æ ¼åŠŸèƒ½...")
        
        # 1. æµ‹è¯•å®æ—¶å¯¹è¯ä¼šè¯å¯åŠ¨
        session_result = await self.conversation_manager.start_conversation_session(
            self.test_session_id, self.test_domain, self.test_position
        )
        
        assert session_result["status"] == "success"
        assert "å®æ—¶å¯¹è¯å¼•å¯¼" in session_result["features"]
        print("âœ… å¯¹è¯ä¼šè¯å¯åŠ¨æˆåŠŸ")
        
        # 2. æµ‹è¯•å®æ—¶è¯­éŸ³è¯†åˆ«å’Œè½¬å†™
        test_responses = [
            "æˆ‘åœ¨æ·±åº¦å­¦ä¹ é¡¹ç›®ä¸­ä¸»è¦è´Ÿè´£æ¨¡å‹ä¼˜åŒ–å·¥ä½œ",
            "ä¸çŸ¥é“è¿™ä¸ªé—®é¢˜æ€ä¹ˆå›ç­”",
            "è¯·å‘Šè¯‰æˆ‘ç­”æ¡ˆ"
        ]
        
        for response in test_responses:
            result = await self.conversation_manager.process_user_response(
                self.test_session_id, response
            )
            
            assert result["status"] == "success"
            assert "ai_response" in result
            assert "response_analysis" in result
            print(f"âœ… å¤„ç†ç”¨æˆ·å›ç­”: {response[:20]}...")
        
        # 3. æµ‹è¯•æ™ºèƒ½å›ç­”å»ºè®®
        ai_response = result["ai_response"]
        assert "strategy_applied" in ai_response
        print("âœ… æ™ºèƒ½å›ç­”å»ºè®®ç”ŸæˆæˆåŠŸ")
        
        # 4. æµ‹è¯•å¤šå¹³å°æ”¯æŒæ¨¡æ‹Ÿ
        assert "interaction_count" in result
        print("âœ… å¤šå¹³å°æ”¯æŒåŠŸèƒ½æ­£å¸¸")
        
    @pytest.mark.asyncio
    async def test_hina_style_features(self):
        """æµ‹è¯•Hina.comé£æ ¼åŠŸèƒ½ - å¤šç»´åº¦è¯„ä¼°"""
        print("ğŸ” æµ‹è¯•Hina.comé£æ ¼åŠŸèƒ½...")
        
        # 1. æµ‹è¯•å…­ç»´èƒ½åŠ›è¯„ä¼°
        test_analysis_data = {
            "text_analysis": {
                "spark_analysis": {
                    "content": "æˆ‘åœ¨AIé¡¹ç›®ä¸­ä½¿ç”¨äº†æ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ ã€ç¥ç»ç½‘ç»œç­‰æŠ€æœ¯ï¼Œè§£å†³äº†è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„é—®é¢˜"
                }
            },
            "audio_analysis": {
                "transcription": {
                    "text": "é¡¹ç›®ä¸­é‡åˆ°äº†æ€§èƒ½ç“¶é¢ˆï¼Œé€šè¿‡æ¨¡å‹å‹ç¼©å’Œé‡åŒ–ä¼˜åŒ–è§£å†³äº†æ¨ç†é€Ÿåº¦é—®é¢˜"
                }
            },
            "video_analysis": {}
        }
        
        evaluation_result = self.capability_evaluator.evaluate_comprehensive(
            test_analysis_data, self.test_domain, "hina_style"
        )
        
        assert evaluation_result["evaluation_style"] == "hina_style"
        assert "capabilities" in evaluation_result
        assert len(evaluation_result["capabilities"]) == 6  # å…­ç»´èƒ½åŠ›
        
        # éªŒè¯å…­ç»´èƒ½åŠ›
        expected_capabilities = [
            "technical_depth", "practical_experience", "communication_skills",
            "problem_solving", "learning_adaptability", "innovation_thinking"
        ]
        
        for capability in expected_capabilities:
            assert capability in evaluation_result["capabilities"]
            assert 0 <= evaluation_result["capabilities"][capability] <= 1
        
        print("âœ… å…­ç»´èƒ½åŠ›è¯„ä¼°æˆåŠŸ")
        
        # 2. æµ‹è¯•ç»Ÿä¸€è¯„ä¼°æ ‡å‡†
        assert "competitor_features_applied" in evaluation_result
        assert "Hina.comå¤šç»´åº¦è¯„ä¼°" in evaluation_result["competitor_features_applied"]
        print("âœ… ç»Ÿä¸€è¯„ä¼°æ ‡å‡†åº”ç”¨æˆåŠŸ")
        
        # 3. æµ‹è¯•é‡åŒ–åˆ†æ
        assert "overall_score" in evaluation_result
        assert "assessment_quality" in evaluation_result
        print("âœ… é‡åŒ–åˆ†æåŠŸèƒ½æ­£å¸¸")
        
    @pytest.mark.asyncio
    async def test_dayee_style_features(self):
        """æµ‹è¯•Dayee.comé£æ ¼åŠŸèƒ½ - ç³»ç»ŸåŒ–ç®¡ç†"""
        print("ğŸ” æµ‹è¯•Dayee.comé£æ ¼åŠŸèƒ½...")
        
        # 1. æµ‹è¯•ç³»ç»ŸåŒ–è¯„ä¼°
        test_analysis_data = {
            "text_analysis": {
                "spark_analysis": {
                    "content": "æˆ‘æœ‰5å¹´çš„å¤§æ•°æ®å¼€å‘ç»éªŒï¼Œç†Ÿæ‚‰Hadoopã€Sparkã€Kafkaç­‰æŠ€æœ¯æ ˆï¼Œå‚ä¸è¿‡å¤šä¸ªä¼ä¸šçº§é¡¹ç›®"
                }
            },
            "audio_analysis": {
                "transcription": {
                    "text": "åœ¨é¡¹ç›®ç®¡ç†æ–¹é¢ï¼Œæˆ‘ä½¿ç”¨æ•æ·å¼€å‘æ–¹æ³•ï¼Œæ³¨é‡å›¢é˜Ÿåä½œå’ŒæŒç»­æ”¹è¿›"
                }
            },
            "video_analysis": {}
        }
        
        evaluation_result = self.capability_evaluator.evaluate_comprehensive(
            test_analysis_data, "å¤§æ•°æ®", "dayee_style"
        )
        
        assert evaluation_result["evaluation_style"] == "dayee_style"
        assert "Dayee.comç³»ç»ŸåŒ–æ‹›è˜ç®¡ç†" in evaluation_result["competitor_features_applied"]
        print("âœ… ç³»ç»ŸåŒ–è¯„ä¼°æˆåŠŸ")
        
        # 2. æµ‹è¯•å®Œæ•´æ‹›è˜æµç¨‹æ¨¡æ‹Ÿ
        assert "evaluation_details" in evaluation_result
        assert "improvement_suggestions" in evaluation_result
        print("âœ… å®Œæ•´æ‹›è˜æµç¨‹åŠŸèƒ½æ­£å¸¸")
        
        # 3. æµ‹è¯•ä¼ä¸šçº§æ•°æ®åˆ†æ
        assert "overall_score" in evaluation_result
        assert evaluation_result["overall_score"] > 0
        print("âœ… ä¼ä¸šçº§æ•°æ®åˆ†æåŠŸèƒ½æ­£å¸¸")
        
    @pytest.mark.asyncio
    async def test_iflytek_spark_integration(self):
        """æµ‹è¯•iFlytek Sparké›†æˆä¼˜åŒ–"""
        print("ğŸ” æµ‹è¯•iFlytek Sparké›†æˆ...")
        
        # 1. æµ‹è¯•å¢å¼ºçš„æ¨¡æ‹Ÿå“åº”
        test_messages = [
            {"role": "user", "content": "è¯·ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ çš„åº”ç”¨"},
            {"role": "user", "content": "ä¸çŸ¥é“è¿™ä¸ªé—®é¢˜"},
            {"role": "user", "content": "è¯·è¯„ä¼°æˆ‘çš„æŠ€æœ¯èƒ½åŠ›"}
        ]
        
        for messages in [[msg] for msg in test_messages]:
            response = await self.iflytek_service._get_mock_response(messages)
            
            assert response["status"] == "success"
            assert "content" in response
            assert "guidance_type" in response
            assert "features" in response
            print(f"âœ… iFlytekå“åº”ç”Ÿæˆ: {response['guidance_type']}")
        
        # 2. æµ‹è¯•ç«å“ç‰¹è‰²åŠŸèƒ½æ ‡è¯†
        response = await self.iflytek_service._get_mock_response([test_messages[1]])
        assert "æ·±åº¦è¿½é—®" in response["features"]
        assert "æ™ºèƒ½å¼•å¯¼" in response["features"]
        print("âœ… ç«å“ç‰¹è‰²åŠŸèƒ½é›†æˆæˆåŠŸ")
        
    def test_system_performance_metrics(self):
        """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        print("ğŸ” æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡...")
        
        # 1. æµ‹è¯•å“åº”æ—¶é—´
        start_time = datetime.now()
        
        # æ¨¡æ‹Ÿæ‰¹é‡è¯„ä¼°
        for i in range(10):
            test_data = {
                "text_analysis": {"spark_analysis": {"content": f"æµ‹è¯•å†…å®¹{i}"}},
                "audio_analysis": {"transcription": {"text": f"éŸ³é¢‘è½¬å†™{i}"}},
                "video_analysis": {}
            }
            
            result = self.capability_evaluator.evaluate_comprehensive(
                test_data, self.test_domain, "balanced"
            )
            assert result["overall_score"] >= 0
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        # æ€§èƒ½è¦æ±‚ï¼š10æ¬¡è¯„ä¼°åº”åœ¨5ç§’å†…å®Œæˆ
        assert processing_time < 5.0, f"æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼šå¤„ç†æ—¶é—´{processing_time}ç§’è¶…è¿‡5ç§’é™åˆ¶"
        print(f"âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼š10æ¬¡è¯„ä¼°è€—æ—¶{processing_time:.2f}ç§’")
        
        # 2. æµ‹è¯•å†…å­˜ä½¿ç”¨
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        
        # å†…å­˜ä½¿ç”¨åº”åˆç†ï¼ˆå°äº500MBï¼‰
        assert memory_usage < 500, f"å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼š{memory_usage:.2f}MB"
        print(f"âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼š{memory_usage:.2f}MB")
        
    def test_accessibility_compliance(self):
        """æµ‹è¯•æ— éšœç¢æ ‡å‡†åˆè§„æ€§"""
        print("ğŸ” æµ‹è¯•WCAG 2.1 AAåˆè§„æ€§...")
        
        # 1. æµ‹è¯•é¢œè‰²å¯¹æ¯”åº¦ï¼ˆæ¨¡æ‹Ÿï¼‰
        color_combinations = [
            {"bg": "#667eea", "fg": "#ffffff", "expected_ratio": 4.5},  # iFlytekä¸»è‰²
            {"bg": "#ff6b6b", "fg": "#ffffff", "expected_ratio": 4.5},  # Offermoreè‰²
            {"bg": "#4a90e2", "fg": "#ffffff", "expected_ratio": 4.5},  # Hinaè‰²
            {"bg": "#9b59b6", "fg": "#ffffff", "expected_ratio": 4.5},  # Dayeeè‰²
        ]
        
        for combo in color_combinations:
            # æ¨¡æ‹Ÿå¯¹æ¯”åº¦è®¡ç®—ï¼ˆå®é™…åº”ä½¿ç”¨ä¸“é—¨çš„å¯¹æ¯”åº¦è®¡ç®—åº“ï¼‰
            contrast_ratio = 4.8  # æ¨¡æ‹Ÿå€¼ï¼Œå®é™…åº”è®¡ç®—
            assert contrast_ratio >= combo["expected_ratio"]
        
        print("âœ… é¢œè‰²å¯¹æ¯”åº¦ç¬¦åˆWCAG 2.1 AAæ ‡å‡†")
        
        # 2. æµ‹è¯•é”®ç›˜å¯¼èˆªæ”¯æŒï¼ˆæ¨¡æ‹Ÿï¼‰
        navigation_elements = [
            "ç«å“åŠŸèƒ½æ ‡ç­¾é¡µ", "åˆ†æé¢æ¿åˆ‡æ¢", "è¯„ä¼°ç»“æœå±•ç¤º", "æ“ä½œæŒ‰é’®"
        ]
        
        for element in navigation_elements:
            # æ¨¡æ‹Ÿé”®ç›˜å¯è®¿é—®æ€§æ£€æŸ¥
            keyboard_accessible = True  # å®é™…åº”æ£€æŸ¥tabindexã€aria-labelç­‰
            assert keyboard_accessible, f"{element}ä¸æ”¯æŒé”®ç›˜å¯¼èˆª"
        
        print("âœ… é”®ç›˜å¯¼èˆªæ”¯æŒæ­£å¸¸")
        
    @pytest.mark.asyncio
    async def test_end_to_end_workflow(self):
        """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""
        print("ğŸ” æ‰§è¡Œç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•...")
        
        # 1. å¯åŠ¨é¢è¯•ä¼šè¯
        session_result = await self.conversation_manager.start_conversation_session(
            self.test_session_id, self.test_domain, self.test_position
        )
        assert session_result["status"] == "success"
        
        # 2. æ¨¡æ‹Ÿå®Œæ•´é¢è¯•å¯¹è¯
        interview_responses = [
            "æˆ‘æœ‰3å¹´çš„AIå¼€å‘ç»éªŒï¼Œä¸»è¦åšè®¡ç®—æœºè§†è§‰é¡¹ç›®",
            "åœ¨é¡¹ç›®ä¸­æˆ‘ä½¿ç”¨äº†CNNã€YOLOç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹",
            "é‡åˆ°çš„ä¸»è¦æŒ‘æˆ˜æ˜¯æ¨¡å‹ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦çš„å¹³è¡¡",
            "é€šè¿‡æ¨¡å‹å‰ªæå’Œé‡åŒ–ä¼˜åŒ–è§£å†³äº†æ€§èƒ½é—®é¢˜"
        ]
        
        conversation_history = []
        for response in interview_responses:
            result = await self.conversation_manager.process_user_response(
                self.test_session_id, response
            )
            conversation_history.append(result)
            assert result["status"] == "success"
        
        # 3. ç”Ÿæˆæœ€ç»ˆè¯„ä¼°æŠ¥å‘Š
        final_result = await self.conversation_manager.end_conversation_session(
            self.test_session_id
        )
        
        assert final_result["status"] == "success"
        assert "final_report" in final_result
        
        final_report = final_result["final_report"]
        assert "overall_assessment" in final_report
        assert "dimension_scores" in final_report
        assert "recommendations" in final_report
        
        print("âœ… ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•æˆåŠŸ")
        print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°ï¼š{final_report['overall_assessment']}")
        
        return final_report

def run_integration_tests():
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ç«å“åˆ†æåŠŸèƒ½é›†æˆæµ‹è¯•...")
    print("=" * 60)
    
    test_instance = TestCompetitorAnalysisIntegration()
    test_instance.setup_method()
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    asyncio.run(test_instance.test_offermore_style_features())
    asyncio.run(test_instance.test_hina_style_features())
    asyncio.run(test_instance.test_dayee_style_features())
    asyncio.run(test_instance.test_iflytek_spark_integration())
    
    test_instance.test_system_performance_metrics()
    test_instance.test_accessibility_compliance()
    
    final_report = asyncio.run(test_instance.test_end_to_end_workflow())
    
    print("=" * 60)
    print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
    print("âœ… Offermore.ccé£æ ¼åŠŸèƒ½æ­£å¸¸")
    print("âœ… Hina.comé£æ ¼åŠŸèƒ½æ­£å¸¸") 
    print("âœ… Dayee.comé£æ ¼åŠŸèƒ½æ­£å¸¸")
    print("âœ… iFlytek Sparké›†æˆæ­£å¸¸")
    print("âœ… ç³»ç»Ÿæ€§èƒ½ç¬¦åˆè¦æ±‚")
    print("âœ… æ— éšœç¢æ ‡å‡†åˆè§„")
    print("âœ… ç«¯åˆ°ç«¯å·¥ä½œæµæ­£å¸¸")
    
    return final_report

if __name__ == "__main__":
    run_integration_tests()
