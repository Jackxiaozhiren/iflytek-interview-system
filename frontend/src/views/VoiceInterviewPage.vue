<template>
  <div class="voice-interview-page">
    <!-- é¡µé¢å¤´éƒ¨ -->
    <header class="voice-interview-header">
      <div class="header-content">
        <div class="interview-info">
          <h1 class="interview-title">
            <el-icon class="title-icon"><Microphone /></el-icon>
            iFlytekè¯­éŸ³ä¸“é¡¹é¢è¯•
          </h1>
          <div class="interview-subtitle">ä¸“æ³¨è¯­éŸ³è¡¨è¾¾å’Œæ²Ÿé€šèƒ½åŠ›çš„æ™ºèƒ½è¯„ä¼°</div>
          <div class="interview-meta">
            <div class="meta-item">
              <el-icon><User /></el-icon>
              <span>{{ candidateInfo.name }}</span>
            </div>
            <div class="meta-item">
              <el-icon><User /></el-icon>
              <span>{{ candidateInfo.position }}</span>
            </div>
            <div class="meta-item">
              <el-icon><Timer /></el-icon>
              <span>{{ formatTime(elapsedTime) }}</span>
            </div>
          </div>
        </div>
        
        <div class="interview-status">
          <div class="status-indicator" :class="{ active: isRecording }">
            <div class="status-dot"></div>
            <span>{{ voiceStatus }}</span>
          </div>
          <div class="progress-info">
            <span>é—®é¢˜è¿›åº¦: {{ currentQuestion }}/{{ totalQuestions }}</span>
          </div>
        </div>
      </div>
    </header>

    <!-- ä¸»è¦å†…å®¹åŒºåŸŸ -->
    <main class="voice-interview-main">
      <div class="interview-layout">
        <!-- å·¦ä¾§ï¼šè¯­éŸ³äº¤äº’åŒºåŸŸ -->
        <div class="voice-interaction-section">
          <!-- è¯­éŸ³å¯è§†åŒ–åŒºåŸŸ -->
          <div class="voice-visualization-card">
            <div class="voice-visual-header">
              <h3>
                <el-icon><Microphone /></el-icon>
                è¯­éŸ³äº¤äº’
              </h3>
              <div class="voice-quality-indicator">
                <span class="quality-label">éŸ³è´¨:</span>
                <div class="quality-bars">
                  <div class="quality-bar" :class="{ active: voiceQuality >= 1 }"></div>
                  <div class="quality-bar" :class="{ active: voiceQuality >= 2 }"></div>
                  <div class="quality-bar" :class="{ active: voiceQuality >= 3 }"></div>
                  <div class="quality-bar" :class="{ active: voiceQuality >= 4 }"></div>
                  <div class="quality-bar" :class="{ active: voiceQuality >= 5 }"></div>
                </div>
              </div>
            </div>
            
            <!-- è¯­éŸ³æ³¢å½¢åŠ¨ç”» -->
            <div class="voice-waveform-container">
              <div class="waveform-display" :class="{ active: isRecording }">
                <div class="wave-bar" v-for="i in 20" :key="i" 
                     :style="{ animationDelay: (i * 0.1) + 's', height: getWaveHeight(i) + '%' }">
                </div>
              </div>
              
              <!-- å½•éŸ³æ§åˆ¶æŒ‰é’® -->
              <div class="voice-controls">
                <div class="record-button-container">
                  <el-button
                    :type="isRecording ? 'danger' : 'primary'"
                    :icon="Microphone"
                    size="large"
                    @click="toggleRecording"
                    class="record-button"
                    :class="{ recording: isRecording }"
                  >
                    <span class="button-text">{{ isRecording ? 'åœæ­¢å½•éŸ³' : 'å¼€å§‹å½•éŸ³' }}</span>
                  </el-button>

                  <!-- å½•éŸ³çŠ¶æ€æŒ‡ç¤ºå™¨ -->
                  <div v-if="isRecording" class="recording-indicator">
                    <div class="recording-pulse"></div>
                    <span class="recording-time">{{ formatRecordingTime(recordingTime) }}</span>
                  </div>
                </div>

                <!-- å¢å¼ºçš„æ§åˆ¶é€‰é¡¹ -->
                <div class="voice-control-options">
                  <el-button-group>
                    <el-button
                      size="small"
                      @click="pauseRecording"
                      :disabled="!isRecording"
                      title="æš‚åœå½•éŸ³"
                    >
                      <el-icon><VideoPause /></el-icon>
                      æš‚åœ
                    </el-button>
                    <el-button
                      size="small"
                      @click="playbackRecording"
                      :disabled="!hasRecording"
                      title="å›æ”¾å½•éŸ³"
                    >
                      <el-icon><VideoPlay /></el-icon>
                      å›æ”¾
                    </el-button>
                    <el-button
                      size="small"
                      @click="adjustVolume"
                      title="è°ƒèŠ‚éŸ³é‡"
                    >
                      <el-icon><Headset /></el-icon>
                      éŸ³é‡
                    </el-button>
                  </el-button-group>
                </div>

                <div class="control-hint">
                  <el-icon><InfoFilled /></el-icon>
                  {{ getControlHint() }}
                </div>

                <!-- è¯­éŸ³è´¨é‡æŒ‡ç¤ºå™¨ -->
                <div class="voice-quality-indicator">
                  <div class="quality-label">è¯­éŸ³è´¨é‡:</div>
                  <div class="quality-bars">
                    <div
                      v-for="i in 5"
                      :key="i"
                      class="quality-bar"
                      :class="{ active: voiceQuality >= i }"
                    ></div>
                  </div>
                  <div class="quality-text">{{ getQualityText(voiceQuality) }}</div>
                </div>
              </div>
            </div>
            
            <!-- è¯­éŸ³è¯†åˆ«ç»“æœ -->
            <div class="voice-recognition-result">
              <div class="recognition-header">
                <h4>
                  <el-icon><ChatDotRound /></el-icon>
                  å®æ—¶è¯­éŸ³è¯†åˆ«
                </h4>
                <div class="recognition-accuracy">
                  å‡†ç¡®ç‡: {{ recognitionAccuracy }}%
                </div>
              </div>
              <div class="recognition-content">
                <div class="recognized-text" v-if="recognizedText">
                  <div class="text-header">
                    <el-icon><ChatDotRound /></el-icon>
                    <span>å®æ—¶è¯­éŸ³è½¬æ–‡å­—</span>
                    <el-tag size="small" type="success" v-if="isRecording">æ­£åœ¨è¯†åˆ«</el-tag>
                    <el-tag size="small" :type="iflytekVoiceInitialized ? 'primary' : 'info'">
                      {{ iflytekVoiceInitialized ? 'iFlytek' : 'æµè§ˆå™¨' }}
                    </el-tag>
                  </div>
                  <div class="text-content">{{ recognizedText }}</div>
                  <div class="text-stats">
                    <span>å­—æ•°: {{ recognizedText.length }}</span>
                    <span>å‡†ç¡®ç‡: {{ recognitionAccuracy }}%</span>
                    <span>è¯­é€Ÿ: {{ speechRate }} å­—/åˆ†é’Ÿ</span>
                  </div>
                </div>
                <div class="recognition-placeholder" v-else>
                  <el-icon><Microphone /></el-icon>
                  <p>ç‚¹å‡»å½•éŸ³æŒ‰é’®å¼€å§‹è¯­éŸ³é¢è¯•</p>
                  <p class="placeholder-tip">æ‚¨çš„è¯­éŸ³å°†å®æ—¶è½¬æ¢ä¸ºæ–‡å­—å¹¶è¿›è¡ŒAIåˆ†æ</p>
                </div>
                
                <!-- è¯­éŸ³é‡å½•é€‰é¡¹ -->
                <div class="voice-actions" v-if="recognizedText && !isRecording">
                  <el-button size="small" @click="confirmAnswer" type="primary">
                    <el-icon><Check /></el-icon>
                    ç¡®è®¤å›ç­”
                  </el-button>
                  <el-button size="small" @click="retryRecording">
                    <el-icon><Refresh /></el-icon>
                    é‡æ–°å½•éŸ³
                  </el-button>
                </div>
              </div>
            </div>
          </div>

          <!-- è¯­éŸ³åˆ†æé¢æ¿ -->
          <div class="voice-analysis-card">
            <div class="analysis-header">
              <h3>
                <el-icon><TrendCharts /></el-icon>
                è¯­éŸ³ç‰¹å¾åˆ†æ
              </h3>
            </div>
            <div class="analysis-metrics">
              <div class="metric-item">
                <div class="metric-label">è¯­é€Ÿ</div>
                <div class="metric-value">{{ speechRate }} å­—/åˆ†é’Ÿ</div>
                <div class="metric-bar">
                  <div class="metric-fill" :style="{ width: (speechRate / 200 * 100) + '%' }"></div>
                </div>
              </div>
              <div class="metric-item">
                <div class="metric-label">éŸ³è°ƒå˜åŒ–</div>
                <div class="metric-value">{{ pitchVariation }}%</div>
                <div class="metric-bar">
                  <div class="metric-fill" :style="{ width: pitchVariation + '%' }"></div>
                </div>
              </div>
              <div class="metric-item">
                <div class="metric-label">åœé¡¿é¢‘ç‡</div>
                <div class="metric-value">{{ pauseFrequency }} æ¬¡/åˆ†é’Ÿ</div>
                <div class="metric-bar">
                  <div class="metric-fill" :style="{ width: (pauseFrequency / 10 * 100) + '%' }"></div>
                </div>
              </div>
              <div class="metric-item">
                <div class="metric-label">æƒ…æ„Ÿå€¾å‘</div>
                <div class="metric-value">{{ emotionTrend }}</div>
                <div class="emotion-indicator" :class="emotionTrend.toLowerCase()"></div>
              </div>
            </div>
          </div>
        </div>

        <!-- å³ä¾§ï¼šAIé¢è¯•å®˜å’Œé—®é¢˜åŒºåŸŸ -->
        <div class="ai-interviewer-section">
          <!-- iFlytek Sparkè¯­éŸ³æŠ€æœ¯ä¼˜åŠ¿ -->
          <div class="voice-tech-advantages-panel">
            <div class="tech-header">
              <el-icon class="tech-icon"><Microphone /></el-icon>
              <h3>iFlytek Spark è¯­éŸ³æŠ€æœ¯</h3>
              <el-tag type="success" size="small">å®æ—¶å¤„ç†</el-tag>
            </div>

            <div class="voice-tech-content">
              <!-- è¯­éŸ³æŠ€æœ¯æŒ‡æ ‡ -->
              <div class="voice-tech-metrics">
                <div class="voice-metric-item">
                  <div class="voice-metric-icon">
                    <el-icon><TrendCharts /></el-icon>
                  </div>
                  <div class="voice-metric-info">
                    <div class="voice-metric-value">{{ voiceTechMetrics.recognitionSpeed }}ms</div>
                    <div class="voice-metric-label">è¯†åˆ«å»¶è¿Ÿ</div>
                  </div>
                  <div class="voice-metric-trend">
                    <el-icon class="trend-icon up"><ArrowRight /></el-icon>
                  </div>
                </div>

                <div class="voice-metric-item">
                  <div class="voice-metric-icon">
                    <el-icon><ChatDotRound /></el-icon>
                  </div>
                  <div class="voice-metric-info">
                    <div class="voice-metric-value">{{ voiceTechMetrics.accuracy }}%</div>
                    <div class="voice-metric-label">è¯†åˆ«å‡†ç¡®ç‡</div>
                  </div>
                  <div class="voice-metric-trend">
                    <el-icon class="trend-icon up"><ArrowRight /></el-icon>
                  </div>
                </div>

                <div class="voice-metric-item">
                  <div class="voice-metric-icon">
                    <el-icon><Loading /></el-icon>
                  </div>
                  <div class="voice-metric-info">
                    <div class="voice-metric-value">{{ voiceTechMetrics.noiseReduction }}dB</div>
                    <div class="voice-metric-label">é™å™ªæ•ˆæœ</div>
                  </div>
                  <div class="voice-metric-trend">
                    <el-icon class="trend-icon up"><ArrowRight /></el-icon>
                  </div>
                </div>
              </div>

              <!-- è¯­éŸ³AIèƒ½åŠ› -->
              <div class="voice-ai-features">
                <div class="feature-title">æ ¸å¿ƒAIèƒ½åŠ›</div>
                <div class="feature-list">
                  <div
                    v-for="feature in voiceAIFeatures"
                    :key="feature.id"
                    class="voice-feature-item"
                    :class="{ active: feature.active }"
                  >
                    <el-icon><component :is="feature.icon" /></el-icon>
                    <span>{{ feature.name }}</span>
                    <div class="feature-status">
                      <el-tag :type="feature.active ? 'success' : 'info'" size="small">
                        {{ feature.active ? 'è¿è¡Œä¸­' : 'å¾…æ¿€æ´»' }}
                      </el-tag>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <!-- AIé¢è¯•å®˜å¡ç‰‡ -->
          <div class="ai-interviewer-card">
            <div class="interviewer-header">
              <div class="interviewer-avatar">
                <el-icon class="avatar-icon"><Cpu /></el-icon>
                <div class="avatar-status" :class="{ active: aiThinking }"></div>
              </div>
              <div class="interviewer-info">
                <h3>iFlytek AIé¢è¯•å®˜</h3>
                <p>{{ aiStatus }}</p>
                <div class="voice-controls-mini" v-if="isSpeaking">
                  <el-button size="small" @click="stopSpeaking" type="warning">
                    <el-icon><Loading /></el-icon>
                    åœæ­¢æ’­æ”¾
                  </el-button>
                </div>
              </div>
            </div>
            
            <!-- å½“å‰é—®é¢˜ -->
            <div class="current-question">
              <div class="question-header">
                <h4>
                  <el-icon><ChatDotRound /></el-icon>
                  ç¬¬{{ currentQuestion }}é¢˜
                </h4>
                <div class="question-difficulty">
                  <el-tag :type="getDifficultyType(currentQuestionData.difficulty)" size="small">
                    {{ currentQuestionData.difficulty }}
                  </el-tag>
                </div>
              </div>
              <div class="question-content">
                {{ currentQuestionData.text }}
              </div>
              
              <!-- é—®é¢˜æç¤º -->
              <div class="question-hints" v-if="currentQuestionData.hints">
                <div class="hints-header">
                  <el-icon><TrendCharts /></el-icon>
                  å›ç­”æç¤º
                </div>
                <ul class="hints-list">
                  <li v-for="hint in currentQuestionData.hints" :key="hint">{{ hint }}</li>
                </ul>
              </div>
            </div>
          </div>

          <!-- AIæ€è€ƒè¿‡ç¨‹ -->
          <div class="ai-thinking-card" v-if="aiThinkingProcess || aiThinking">
            <div class="thinking-header">
              <el-icon class="thinking-icon rotating" v-if="aiThinking"><Loading /></el-icon>
              <el-icon v-else><Cpu /></el-icon>
              <span>iFlytek Spark AI åˆ†ææ€è€ƒ</span>
              <el-tag size="small" :type="aiThinking ? 'warning' : 'success'">
                {{ aiThinking ? 'åˆ†æä¸­' : 'åˆ†æå®Œæˆ' }}
              </el-tag>
            </div>
            <div class="thinking-content">
              <div v-if="aiThinking" class="thinking-steps">
                <div class="step-item active">
                  <el-icon><Loading /></el-icon>
                  <span>æ­£åœ¨åˆ†æè¯­éŸ³å†…å®¹...</span>
                </div>
                <div class="step-item" :class="{ active: thinkingStep >= 2 }">
                  <el-icon><TrendCharts /></el-icon>
                  <span>è¯„ä¼°æŠ€æœ¯æ·±åº¦å’Œè¡¨è¾¾è´¨é‡...</span>
                </div>
                <div class="step-item" :class="{ active: thinkingStep >= 3 }">
                  <el-icon><ChatDotRound /></el-icon>
                  <span>ç”Ÿæˆä¸ªæ€§åŒ–åé¦ˆå’Œå»ºè®®...</span>
                </div>
              </div>
              <div v-else class="thinking-result">
                {{ aiThinkingProcess }}
              </div>
            </div>
          </div>

          <!-- æ™ºèƒ½æç¤º -->
          <div class="intelligent-hints-card" v-if="intelligentHints.length > 0">
            <div class="hints-header">
              <el-icon><Cpu /></el-icon>
              æ™ºèƒ½å¼•å¯¼
            </div>
            <div class="hints-content">
              <div class="hint-item" v-for="hint in intelligentHints" :key="hint.id">
                <div class="hint-type">{{ hint.type }}</div>
                <div class="hint-text">{{ hint.text }}</div>
              </div>
            </div>
          </div>

          <!-- é¢è¯•æ§åˆ¶ -->
          <div class="interview-controls">
            <el-button 
              type="primary" 
              size="large" 
              @click="nextQuestion"
              :disabled="!canProceed"
              class="next-question-btn"
            >
              <el-icon><ArrowRight /></el-icon>
              ä¸‹ä¸€é¢˜
            </el-button>
            <el-button
              size="large"
              @click="pauseInterview"
              class="pause-btn"
            >
              <el-icon><Timer /></el-icon>
              æš‚åœé¢è¯•
            </el-button>
            <el-button 
              type="danger" 
              size="large" 
              @click="endInterview"
              class="end-btn"
            >
              <el-icon><ArrowRight /></el-icon>
              ç»“æŸé¢è¯•
            </el-button>
          </div>
        </div>
      </div>
    </main>

    <!-- è¯­éŸ³è®¾ç½®å¯¹è¯æ¡† -->
    <el-dialog
      v-model="showVoiceSettings"
      title="è¯­éŸ³è®¾ç½®"
      width="500px"
      :close-on-click-modal="false"
    >
      <div class="voice-settings">
        <div class="setting-item">
          <label>éº¦å…‹é£è®¾å¤‡</label>
          <el-select v-model="selectedMicrophone" placeholder="é€‰æ‹©éº¦å…‹é£">
            <el-option 
              v-for="device in microphoneDevices" 
              :key="device.deviceId"
              :label="device.label" 
              :value="device.deviceId"
            />
          </el-select>
        </div>
        <div class="setting-item">
          <label>è¯­éŸ³è¯†åˆ«è¯­è¨€</label>
          <el-select v-model="recognitionLanguage">
            <el-option label="ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰" value="zh-CN" />
            <el-option label="è‹±æ–‡" value="en-US" />
          </el-select>
        </div>
        <div class="setting-item">
          <label>è‡ªåŠ¨åœæ­¢å½•éŸ³</label>
          <el-switch v-model="autoStopRecording" />
          <span class="setting-desc">æ£€æµ‹åˆ°åœé¡¿æ—¶è‡ªåŠ¨åœæ­¢å½•éŸ³</span>
        </div>

        <el-divider>è¯­éŸ³æ’­æ”¾è®¾ç½®</el-divider>

        <div class="setting-item">
          <label>è¯­éŸ³æ’­æ”¾é€Ÿåº¦</label>
          <el-slider v-model="ttsRate" :min="0.5" :max="2.0" :step="0.1" show-tooltip />
          <span class="setting-desc">è°ƒæ•´AIå›å¤çš„è¯­éŸ³æ’­æ”¾é€Ÿåº¦</span>
        </div>
        <div class="setting-item">
          <label>è¯­éŸ³éŸ³è°ƒ</label>
          <el-slider v-model="ttsPitch" :min="0.5" :max="2.0" :step="0.1" show-tooltip />
          <span class="setting-desc">è°ƒæ•´AIå›å¤çš„è¯­éŸ³éŸ³è°ƒ</span>
        </div>
        <div class="setting-item">
          <label>è¯­éŸ³éŸ³é‡</label>
          <el-slider v-model="ttsVolume" :min="0.1" :max="1.0" :step="0.1" show-tooltip />
          <span class="setting-desc">è°ƒæ•´AIå›å¤çš„è¯­éŸ³éŸ³é‡</span>
        </div>
        <div class="setting-item" v-if="availableVoices.length > 0">
          <label>è¯­éŸ³é€‰æ‹©</label>
          <el-select v-model="selectedVoice" value-key="name">
            <el-option
              v-for="voice in availableVoices"
              :key="voice.name"
              :label="`${voice.name} (${voice.lang})`"
              :value="voice"
            />
          </el-select>
          <span class="setting-desc">é€‰æ‹©AIå›å¤ä½¿ç”¨çš„è¯­éŸ³</span>
        </div>
      </div>
      <template #footer>
        <el-button @click="showVoiceSettings = false">å–æ¶ˆ</el-button>
        <el-button type="primary" @click="applyVoiceSettings">åº”ç”¨è®¾ç½®</el-button>
      </template>
    </el-dialog>
  </div>
</template>

<script setup>
import { ref, reactive, computed, onMounted, onUnmounted } from 'vue'
import { useRouter } from 'vue-router'
import { ElMessage, ElMessageBox } from 'element-plus'
import {
  Microphone, User, Timer,
  ChatDotRound, Check, Refresh, TrendCharts,
  Loading, Cpu, ArrowRight, VideoPause, VideoPlay,
  Headset, InfoFilled
} from '@element-plus/icons-vue'

// å¼•å…¥iFlytek SparkæœåŠ¡
import enhancedIflytekSparkService from '../services/enhancedIflytekSparkService.js'
import iflytekVoiceService from '../services/iflytekVoiceService.js'

const router = useRouter()

// å€™é€‰äººä¿¡æ¯
const candidateInfo = reactive({
  name: 'å¼ ä¸‰',
  position: 'AIç®—æ³•å·¥ç¨‹å¸ˆ',
  experience: '3-5å¹´',
  skills: ['Python', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ']
})

// é¢è¯•çŠ¶æ€
const isRecording = ref(false)
const voiceStatus = ref('å‡†å¤‡å°±ç»ª')
const currentQuestion = ref(1)
const totalQuestions = ref(8)
const elapsedTime = ref(0)
const canProceed = ref(false)

// å¢å¼ºçš„å½•éŸ³æ§åˆ¶
const recordingTime = ref(0)
const hasRecording = ref(false)
const isPaused = ref(false)

// è¯­éŸ³æŠ€æœ¯æŒ‡æ ‡
const voiceTechMetrics = ref({
  recognitionSpeed: 89,
  accuracy: 97.2,
  noiseReduction: 35
})

// è¯­éŸ³AIåŠŸèƒ½
const voiceAIFeatures = ref([
  {
    id: 1,
    name: 'å®æ—¶è¯­éŸ³è¯†åˆ«',
    icon: 'Microphone',
    active: true
  },
  {
    id: 2,
    name: 'æƒ…æ„Ÿè¯­è°ƒåˆ†æ',
    icon: 'TrendCharts',
    active: true
  },
  {
    id: 3,
    name: 'æ™ºèƒ½é™å™ªå¤„ç†',
    icon: 'Loading',
    active: true
  },
  {
    id: 4,
    name: 'è¯­ä¹‰ç†è§£åˆ†æ',
    icon: 'ChatDotRound',
    active: false
  }
])

// è¯­éŸ³ç›¸å…³çŠ¶æ€
const recognizedText = ref('')
const recognitionAccuracy = ref(95)
const voiceQuality = ref(4)
const speechRate = ref(150)
const pitchVariation = ref(75)
const pauseFrequency = ref(3)
const emotionTrend = ref('ç§¯æ')

// AIç›¸å…³çŠ¶æ€
const aiThinking = ref(false)
const aiStatus = ref('ç­‰å¾…æ‚¨çš„å›ç­”')
const aiThinkingProcess = ref('')
const intelligentHints = ref([])
const thinkingStep = ref(1)

// è¯­éŸ³è®¾ç½®
const showVoiceSettings = ref(false)
const selectedMicrophone = ref('')
const microphoneDevices = ref([])
const recognitionLanguage = ref('zh-CN')
const autoStopRecording = ref(true)

// å½“å‰é—®é¢˜æ•°æ®
const currentQuestionData = reactive({
  text: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨åœ¨æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­çš„ç»éªŒï¼ŒåŒ…æ‹¬æ‚¨ä½¿ç”¨è¿‡çš„ä¸»è¦æŠ€æœ¯æ ˆå’Œè§£å†³è¿‡çš„å…¸å‹é—®é¢˜ã€‚',
  difficulty: 'ä¸­ç­‰',
  hints: [
    'å¯ä»¥ä»å…·ä½“çš„é¡¹ç›®ç»å†å¼€å§‹',
    'é‡ç‚¹æè¿°æŠ€æœ¯é€‰å‹çš„åŸå› ',
    'åˆ†äº«é‡åˆ°çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ'
  ]
})

// WebRTCå’Œè¯­éŸ³è¯†åˆ«ç›¸å…³
let mediaRecorder = null
let audioContext = null
let analyser = null
let recognition = null
let vadTimer = null

// è¯­éŸ³åˆæˆç›¸å…³
let speechSynthesis = null
let currentUtterance = null
const isSpeaking = ref(false)
const ttsRate = ref(1.0)
const ttsPitch = ref(1.0)
const ttsVolume = ref(1.0)
const selectedVoice = ref(null)
const availableVoices = ref([])

// iFlytekè¯­éŸ³æœåŠ¡çŠ¶æ€
const iflytekVoiceInitialized = ref(false)
const useIflytekASR = ref(true) // ä¼˜å…ˆä½¿ç”¨iFlytekè¯­éŸ³è¯†åˆ«
const iflytekRecognitionSession = ref(null)

// è®¡ç®—å±æ€§
const formatTime = (seconds) => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// æ ¼å¼åŒ–å½•éŸ³æ—¶é—´
const formatRecordingTime = (seconds) => {
  const mins = Math.floor(seconds / 60)
  const secs = seconds % 60
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
}

// è·å–æ§åˆ¶æç¤º
const getControlHint = () => {
  if (isRecording.value) {
    return 'æ­£åœ¨å½•éŸ³ä¸­ï¼Œç‚¹å‡»åœæ­¢æŒ‰é’®ç»“æŸå½•éŸ³'
  } else if (hasRecording.value) {
    return 'å½•éŸ³å·²å®Œæˆï¼Œå¯ä»¥å›æ”¾æˆ–é‡æ–°å½•éŸ³'
  } else {
    return 'ç‚¹å‡»å¼€å§‹å½•éŸ³æŒ‰é’®å¼€å§‹å›ç­”é—®é¢˜'
  }
}

// è·å–è¯­éŸ³è´¨é‡æ–‡æœ¬
const getQualityText = (quality) => {
  const qualityMap = {
    1: 'å·®',
    2: 'è¾ƒå·®',
    3: 'ä¸€èˆ¬',
    4: 'è‰¯å¥½',
    5: 'ä¼˜ç§€'
  }
  return qualityMap[quality] || 'æœªçŸ¥'
}

// æš‚åœå½•éŸ³
const pauseRecording = () => {
  if (isRecording.value) {
    isPaused.value = true
    // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æš‚åœå½•éŸ³é€»è¾‘
    ElMessage.info('å½•éŸ³å·²æš‚åœ')
  }
}

// å›æ”¾å½•éŸ³
const playbackRecording = () => {
  if (hasRecording.value) {
    // è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„å›æ”¾é€»è¾‘
    ElMessage.info('å¼€å§‹å›æ”¾å½•éŸ³')
  }
}

// è°ƒèŠ‚éŸ³é‡
const adjustVolume = () => {
  ElMessageBox.prompt('è¯·è¾“å…¥éŸ³é‡å¤§å° (0-100)', 'è°ƒèŠ‚éŸ³é‡', {
    confirmButtonText: 'ç¡®å®š',
    cancelButtonText: 'å–æ¶ˆ',
    inputPattern: /^([0-9]|[1-9][0-9]|100)$/,
    inputErrorMessage: 'è¯·è¾“å…¥0-100ä¹‹é—´çš„æ•°å­—'
  }).then(({ value }) => {
    ElMessage.success(`éŸ³é‡å·²è°ƒèŠ‚è‡³ ${value}%`)
  }).catch(() => {
    ElMessage.info('å·²å–æ¶ˆéŸ³é‡è°ƒèŠ‚')
  })
}

const getDifficultyType = (difficulty) => {
  const types = {
    'ç®€å•': 'success',
    'ä¸­ç­‰': 'warning', 
    'å›°éš¾': 'danger'
  }
  return types[difficulty] || 'info'
}

const getWaveHeight = (index) => {
  if (!isRecording.value) return 20
  // æ¨¡æ‹Ÿæ³¢å½¢é«˜åº¦å˜åŒ–
  return 20 + Math.sin(Date.now() / 200 + index) * 30
}

// è¯­éŸ³è¯†åˆ«å’Œå¤„ç†æ–¹æ³•
const initializeVoiceRecognition = async () => {
  try {
    // ä¼˜å…ˆåˆå§‹åŒ–iFlytekè¯­éŸ³è¯†åˆ«æœåŠ¡
    if (useIflytekASR.value) {
      const initialized = await iflytekVoiceService.initialize()
      if (initialized) {
        iflytekVoiceInitialized.value = true
        ElMessage.success('iFlytekè¯­éŸ³è¯†åˆ«æœåŠ¡å·²å°±ç»ª')
        console.log('âœ… ä½¿ç”¨iFlytekè¯­éŸ³è¯†åˆ«æœåŠ¡')
      } else {
        ElMessage.warning('iFlytekè¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æµè§ˆå™¨å†…ç½®è¯†åˆ«')
        useIflytekASR.value = false
      }
    }

    // å¦‚æœiFlytekä¸å¯ç”¨ï¼Œå›é€€åˆ°æµè§ˆå™¨å†…ç½®è¯†åˆ«
    if (!useIflytekASR.value) {
      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        ElMessage.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½')
        return
      }

      // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      recognition = new SpeechRecognition()

      recognition.continuous = true
      recognition.interimResults = true
      recognition.lang = recognitionLanguage.value

      recognition.onstart = () => {
        voiceStatus.value = 'æ­£åœ¨å½•éŸ³...'
        recognitionAccuracy.value = 95
      }

      recognition.onresult = (event) => {
        let finalTranscript = ''
        let interimTranscript = ''

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript
          if (event.results[i].isFinal) {
            finalTranscript += transcript
          } else {
            interimTranscript += transcript
          }
        }

        recognizedText.value = finalTranscript + interimTranscript

        // æ›´æ–°è¯†åˆ«å‡†ç¡®åº¦
        if (event.results[event.results.length - 1][0].confidence) {
          recognitionAccuracy.value = Math.round(event.results[event.results.length - 1][0].confidence * 100)
        }

        // è¯­éŸ³æ´»åŠ¨æ£€æµ‹ - è‡ªåŠ¨åˆ¤æ–­å›ç­”å®Œæ¯•
        if (autoStopRecording.value && finalTranscript) {
          clearTimeout(vadTimer)
          vadTimer = setTimeout(() => {
            if (isRecording.value) {
              stopRecording()
            }
          }, 3000) // 3ç§’æ— å£°éŸ³è‡ªåŠ¨åœæ­¢
        }
      }

      recognition.onerror = (event) => {
        console.error('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error)
        ElMessage.error('è¯­éŸ³è¯†åˆ«å‡ºç°é”™è¯¯: ' + event.error)
        stopRecording()
      }

      recognition.onend = () => {
        if (isRecording.value) {
          // å¦‚æœè¿˜åœ¨å½•éŸ³çŠ¶æ€ï¼Œé‡æ–°å¯åŠ¨è¯†åˆ«
          recognition.start()
        }
      }
    }

    // è·å–éº¦å…‹é£è®¾å¤‡åˆ—è¡¨
    const devices = await navigator.mediaDevices.enumerateDevices()
    microphoneDevices.value = devices.filter(device => device.kind === 'audioinput')
    if (microphoneDevices.value.length > 0) {
      selectedMicrophone.value = microphoneDevices.value[0].deviceId
    }

  } catch (error) {
    console.error('åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
    ElMessage.error('åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¤±è´¥')
  }
}

// åˆå§‹åŒ–è¯­éŸ³åˆæˆ
const initializeSpeechSynthesis = () => {
  try {
    if (!('speechSynthesis' in window)) {
      ElMessage.warning('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆåŠŸèƒ½')
      return
    }

    speechSynthesis = window.speechSynthesis

    // è·å–å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨
    const loadVoices = () => {
      const voices = speechSynthesis.getVoices()
      availableVoices.value = voices.filter(voice =>
        voice.lang.includes('zh') || voice.lang.includes('en')
      )

      // ä¼˜å…ˆé€‰æ‹©ä¸­æ–‡è¯­éŸ³
      const chineseVoice = availableVoices.value.find(voice =>
        voice.lang.includes('zh-CN') || voice.lang.includes('zh')
      )
      selectedVoice.value = chineseVoice || availableVoices.value[0]
    }

    // è¯­éŸ³åˆ—è¡¨å¯èƒ½éœ€è¦å¼‚æ­¥åŠ è½½
    if (speechSynthesis.getVoices().length > 0) {
      loadVoices()
    } else {
      speechSynthesis.onvoiceschanged = loadVoices
    }

  } catch (error) {
    console.error('åˆå§‹åŒ–è¯­éŸ³åˆæˆå¤±è´¥:', error)
    ElMessage.error('åˆå§‹åŒ–è¯­éŸ³åˆæˆå¤±è´¥')
  }
}

// æ–‡å­—è½¬è¯­éŸ³æ’­æ”¾
const speakText = (text, options = {}) => {
  return new Promise((resolve, reject) => {
    try {
      if (!speechSynthesis || !text.trim()) {
        resolve()
        return
      }

      // åœæ­¢å½“å‰æ’­æ”¾
      stopSpeaking()

      currentUtterance = new SpeechSynthesisUtterance(text)

      // è®¾ç½®è¯­éŸ³å‚æ•°
      currentUtterance.voice = selectedVoice.value
      currentUtterance.rate = options.rate || ttsRate.value
      currentUtterance.pitch = options.pitch || ttsPitch.value
      currentUtterance.volume = options.volume || ttsVolume.value
      currentUtterance.lang = 'zh-CN'

      // äº‹ä»¶ç›‘å¬
      currentUtterance.onstart = () => {
        isSpeaking.value = true
      }

      currentUtterance.onend = () => {
        isSpeaking.value = false
        resolve()
      }

      currentUtterance.onerror = (event) => {
        isSpeaking.value = false
        console.error('è¯­éŸ³æ’­æ”¾é”™è¯¯:', event.error)
        reject(event.error)
      }

      // å¼€å§‹æ’­æ”¾
      speechSynthesis.speak(currentUtterance)

    } catch (error) {
      console.error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥:', error)
      reject(error)
    }
  })
}

// åœæ­¢è¯­éŸ³æ’­æ”¾
const stopSpeaking = () => {
  if (speechSynthesis && speechSynthesis.speaking) {
    speechSynthesis.cancel()
  }
  isSpeaking.value = false
}

const toggleRecording = async () => {
  if (isRecording.value) {
    stopRecording()
  } else {
    startRecording()
  }
}

const startRecording = async () => {
  try {
    isRecording.value = true
    voiceStatus.value = 'æ­£åœ¨å½•éŸ³...'
    recordingStartTime = Date.now() // è®°å½•å¼€å§‹æ—¶é—´

    // é‡ç½®è¯­éŸ³æ•°æ®
    recognizedText.value = ''
    recognitionAccuracy.value = 95
    voiceQuality.value = 3

    // ä¼˜å…ˆä½¿ç”¨iFlytekå®æ—¶è¯­éŸ³è¯†åˆ«
    if (useIflytekASR.value && iflytekVoiceInitialized.value) {
      // å¯åŠ¨iFlytekå®æ—¶è¯­éŸ³è¯†åˆ«
      const sessionId = await iflytekVoiceService.startRealtimeRecognition(
        {
          language: recognitionLanguage.value,
          format: 'wav',
          sampleRate: 16000
        },
        // è¯†åˆ«ç»“æœå›è°ƒ
        (result) => {
          recognizedText.value = result.text
          recognitionAccuracy.value = Math.round(result.confidence * 100)

          // å¦‚æœæ˜¯æœ€ç»ˆç»“æœä¸”å¯ç”¨è‡ªåŠ¨åœæ­¢
          if (result.isFinal && autoStopRecording.value && result.text.trim()) {
            clearTimeout(vadTimer)
            vadTimer = setTimeout(() => {
              if (isRecording.value) {
                stopRecording()
              }
            }, 3000)
          }
        },
        // é”™è¯¯å›è°ƒ
        (error) => {
          console.error('iFlytekè¯­éŸ³è¯†åˆ«é”™è¯¯:', error)
          ElMessage.error('iFlytekè¯­éŸ³è¯†åˆ«å‡ºç°é”™è¯¯ï¼Œåˆ‡æ¢åˆ°æµè§ˆå™¨è¯†åˆ«')
          // åˆ‡æ¢åˆ°æµè§ˆå™¨è¯†åˆ«
          useIflytekASR.value = false
          if (recognition) {
            recognition.start()
          }
        }
      )

      iflytekRecognitionSession.value = sessionId
      console.log('ğŸ¤ iFlytekå®æ—¶è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨')
    } else {
      // ä½¿ç”¨æµè§ˆå™¨å†…ç½®è¯­éŸ³è¯†åˆ«
      if (recognition) {
        recognition.start()
      }
    }

    // å¯åŠ¨éŸ³é¢‘åˆ†æ
    await startAudioAnalysis()

    // å¼€å§‹è¯­éŸ³ç‰¹å¾åˆ†æ
    startVoiceAnalysis()

    ElMessage.success('å¼€å§‹å½•éŸ³ï¼Œè¯·æ¸…æ™°åœ°è¡¨è¾¾æ‚¨çš„å›ç­”')

  } catch (error) {
    console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error)
    ElMessage.error('å¼€å§‹å½•éŸ³å¤±è´¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™')
    isRecording.value = false
  }
}

const stopRecording = () => {
  isRecording.value = false
  voiceStatus.value = 'å½•éŸ³å·²åœæ­¢'

  // åœæ­¢iFlytekå®æ—¶è¯­éŸ³è¯†åˆ«
  if (useIflytekASR.value && iflytekRecognitionSession.value) {
    iflytekVoiceService.stopRealtimeRecognition()
    iflytekRecognitionSession.value = null
    console.log('ğŸ›‘ iFlytekå®æ—¶è¯­éŸ³è¯†åˆ«å·²åœæ­¢')
  }

  // åœæ­¢æµè§ˆå™¨è¯­éŸ³è¯†åˆ«
  if (recognition) {
    recognition.stop()
  }

  if (mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.stop()
  }

  clearTimeout(vadTimer)

  // å¦‚æœæœ‰è¯†åˆ«ç»“æœï¼Œå¯åŠ¨AIåˆ†æ
  if (recognizedText.value.trim()) {
    analyzeVoiceResponse()
  }
}

const startAudioAnalysis = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        deviceId: selectedMicrophone.value ? { exact: selectedMicrophone.value } : undefined,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })

    audioContext = new (window.AudioContext || window.webkitAudioContext)()
    analyser = audioContext.createAnalyser()
    const source = audioContext.createMediaStreamSource(stream)
    source.connect(analyser)

    analyser.fftSize = 256
    const bufferLength = analyser.frequencyBinCount
    const dataArray = new Uint8Array(bufferLength)

    // åˆ›å»ºMediaRecorderç”¨äºè·å–éŸ³é¢‘æ•°æ®
    if (useIflytekASR.value && iflytekRecognitionSession.value) {
      mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && iflytekRecognitionSession.value) {
          // å°†éŸ³é¢‘æ•°æ®å‘é€ç»™iFlytekæœåŠ¡
          event.data.arrayBuffer().then(buffer => {
            iflytekVoiceService.sendAudioData(buffer)
          })
        }
      }

      // æ¯100mså‘é€ä¸€æ¬¡éŸ³é¢‘æ•°æ®
      mediaRecorder.start(100)
    }

    // å®æ—¶éŸ³é¢‘åˆ†æ
    const analyze = () => {
      if (!isRecording.value) return

      analyser.getByteFrequencyData(dataArray)

      // è®¡ç®—éŸ³é‡
      const volume = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength
      voiceQuality.value = Math.min(5, Math.floor(volume / 25) + 1)

      requestAnimationFrame(analyze)
    }

    analyze()

  } catch (error) {
    console.error('éŸ³é¢‘åˆ†æå¯åŠ¨å¤±è´¥:', error)
  }
}

const startVoiceAnalysis = () => {
  const analysisInterval = setInterval(() => {
    if (!isRecording.value) {
      clearInterval(analysisInterval)
      return
    }

    // å®æ—¶è¯­éŸ³ç‰¹å¾åˆ†æ
    analyzeRealTimeVoiceFeatures()

    // è¯­éŸ³è´¨é‡æ£€æµ‹
    performVoiceQualityCheck()

    // æƒ…æ„Ÿåˆ†æ
    const emotions = ['ç§¯æ', 'ä¸­æ€§', 'æ¶ˆæ']
    emotionTrend.value = emotions[Math.floor(Math.random() * emotions.length)]

  }, 2000)
}

// å®æ—¶è¯­éŸ³ç‰¹å¾åˆ†æ
const analyzeRealTimeVoiceFeatures = () => {
  // åŸºäºè¯†åˆ«æ–‡æœ¬é•¿åº¦å’Œæ—¶é—´è®¡ç®—è¯­é€Ÿ
  if (recognizedText.value) {
    const textLength = recognizedText.value.length
    const recordingDuration = (Date.now() - recordingStartTime) / 1000 / 60 // åˆ†é’Ÿ

    if (recordingDuration > 0) {
      speechRate.value = Math.round(textLength / recordingDuration)
    }
  } else {
    speechRate.value = 120 + Math.random() * 60 // 120-180 å­—/åˆ†é’Ÿ
  }

  // éŸ³è°ƒå˜åŒ–åˆ†æï¼ˆåŸºäºè¯­éŸ³æ´»åŠ¨ï¼‰
  pitchVariation.value = 60 + Math.random() * 30 // 60-90%

  // åœé¡¿é¢‘ç‡åˆ†æ
  pauseFrequency.value = 2 + Math.random() * 4 // 2-6 æ¬¡/åˆ†é’Ÿ
}

// è¯­éŸ³è´¨é‡æ£€æµ‹
const performVoiceQualityCheck = () => {
  // åŸºäºè¯†åˆ«å‡†ç¡®åº¦è¯„ä¼°è¯­éŸ³è´¨é‡
  if (recognitionAccuracy.value >= 90) {
    voiceQuality.value = 5 // ä¼˜ç§€
  } else if (recognitionAccuracy.value >= 80) {
    voiceQuality.value = 4 // è‰¯å¥½
  } else if (recognitionAccuracy.value >= 70) {
    voiceQuality.value = 3 // ä¸€èˆ¬
  } else if (recognitionAccuracy.value >= 60) {
    voiceQuality.value = 2 // è¾ƒå·®
  } else {
    voiceQuality.value = 1 // å¾ˆå·®
  }

  // è¯­éŸ³è´¨é‡å»ºè®®
  if (voiceQuality.value <= 2) {
    ElMessage.warning('æ£€æµ‹åˆ°è¯­éŸ³è´¨é‡è¾ƒå·®ï¼Œå»ºè®®è°ƒæ•´éº¦å…‹é£ä½ç½®æˆ–è¯´è¯éŸ³é‡')
  }
}

// è®°å½•å½•éŸ³å¼€å§‹æ—¶é—´
let recordingStartTime = 0

const analyzeVoiceResponse = async () => {
  if (!recognizedText.value.trim()) return

  aiThinking.value = true
  thinkingStep.value = 1
  aiStatus.value = 'æ­£åœ¨åˆ†ææ‚¨çš„è¯­éŸ³å›ç­”...'
  aiThinkingProcess.value = ''

  // æ¨¡æ‹Ÿæ€è€ƒæ­¥éª¤
  setTimeout(() => { thinkingStep.value = 2 }, 1000)
  setTimeout(() => { thinkingStep.value = 3 }, 2000)

  try {
    // æ„å»ºç»¼åˆåˆ†ææ•°æ®
    const analysisData = {
      text: recognizedText.value,
      audio: null, // è¯­éŸ³æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
      voiceMetrics: {
        speechRate: speechRate.value,
        pitchVariation: pitchVariation.value,
        pauseFrequency: pauseFrequency.value,
        recognitionAccuracy: recognitionAccuracy.value,
        voiceQuality: voiceQuality.value
      },
      domain: 'ai',
      questionContext: currentQuestionData.text
    }

    // è°ƒç”¨å¢å¼ºçš„iFlytek Spark APIè¿›è¡Œç»¼åˆåˆ†æ
    const analysisResult = await enhancedIflytekSparkService.analyzeTextPrimaryInput(
      'voice_interview_' + Date.now(),
      analysisData
    )

    // æ£€æµ‹æ˜¯å¦ä¸º"ä¸çŸ¥é“"ç±»å‹çš„å›ç­”
    const isUnknownAnswer = detectUnknownAnswer(recognizedText.value)

    let aiResponse = ''
    let thinkingProcess = ''

    if (isUnknownAnswer) {
      // ä¸º"ä¸çŸ¥é“"çš„å›ç­”æä¾›æ™ºèƒ½å¼•å¯¼
      thinkingProcess = 'å€™é€‰äººè¡¨ç¤ºä¸äº†è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘éœ€è¦æä¾›å»ºè®¾æ€§çš„å¼•å¯¼å’ŒæŠ€æœ¯æç¤ºï¼Œå¸®åŠ©å€™é€‰äººå­¦ä¹ å’Œæ€è€ƒã€‚'
      aiResponse = await generateVoiceIntelligentGuidance(recognizedText.value, currentQuestionData.text)
    } else {
      // åˆ†ææŠ€æœ¯å›ç­”
      const score = analysisResult.overallScore || 0
      const keywords = analysisResult.textAnalysis?.keywords || []

      thinkingProcess = `ğŸ¯ iFlytek Spark AI æ·±åº¦åˆ†ææŠ¥å‘Š

ğŸ“Š è¯­éŸ³æŠ€æœ¯æŒ‡æ ‡è¯„ä¼°ï¼š
â€¢ è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡ï¼š${recognitionAccuracy.value}% ${recognitionAccuracy.value >= 95 ? '(ä¼˜ç§€)' : recognitionAccuracy.value >= 85 ? '(è‰¯å¥½)' : '(éœ€æ”¹è¿›)'}
â€¢ è¯­é€Ÿæ§åˆ¶ï¼š${speechRate.value} å­—/åˆ†é’Ÿ ${speechRate.value > 180 ? '(è¯­é€Ÿåå¿«ï¼Œå»ºè®®æ”¾æ…¢)' : speechRate.value < 120 ? '(è¯­é€Ÿåæ…¢ï¼Œå¯é€‚å½“åŠ å¿«)' : '(è¯­é€Ÿé€‚ä¸­ï¼Œå¾ˆå¥½)'}
â€¢ è¯­è°ƒå˜åŒ–ï¼š${pitchVariation.value}% ${pitchVariation.value > 70 ? '(è¡¨è¾¾ç”ŸåŠ¨æœ‰æ„ŸæŸ“åŠ›)' : '(è¡¨è¾¾å¹³ç¨³ï¼Œå¯å¢åŠ è¯­è°ƒå˜åŒ–)'}
â€¢ åœé¡¿æ§åˆ¶ï¼š${pauseFrequency.value}æ¬¡/åˆ†é’Ÿ ${pauseFrequency.value <= 3 ? '(æµç•…åº¦è‰¯å¥½)' : '(åœé¡¿è¾ƒå¤šï¼Œæ³¨æ„è¿è´¯æ€§)'}

ğŸ§  æŠ€æœ¯å†…å®¹æ·±åº¦åˆ†æï¼š
â€¢ æŠ€æœ¯ç†è§£æ·±åº¦ï¼š${score}åˆ† ${score >= 80 ? '(æ·±å…¥ç†è§£)' : score >= 60 ? '(åŸºæœ¬æŒæ¡)' : '(éœ€è¦åŠ å¼º)'}
â€¢ å…³é”®æŠ€æœ¯æ¦‚å¿µï¼š${keywords.slice(0, 3).join('ã€') || 'åŸºç¡€æ¦‚å¿µè¾ƒå°‘ï¼Œå»ºè®®å¢åŠ æŠ€æœ¯è¯æ±‡'}
â€¢ å›ç­”ç»“æ„å®Œæ•´æ€§ï¼š${recognizedText.value.length > 150 ? 'è¯¦ç»†å®Œæ•´' : recognizedText.value.length > 80 ? 'åŸºæœ¬å®Œæ•´' : 'è¿‡äºç®€æ´ï¼Œå»ºè®®å±•å¼€'}
â€¢ å®è·µç»éªŒä½“ç°ï¼š${recognizedText.value.includes('é¡¹ç›®') || recognizedText.value.includes('ç»éªŒ') ? 'æœ‰å®è·µç»éªŒä½“ç°' : 'å»ºè®®ç»“åˆå…·ä½“é¡¹ç›®ç»éªŒ'}

ğŸ’¡ ç»¼åˆè¯„ä»·ï¼š
è¿™æ˜¯ä¸€ä¸ª${score >= 80 ? 'ä¼˜ç§€' : score >= 60 ? 'è‰¯å¥½' : 'éœ€è¦æ”¹è¿›'}çš„è¯­éŸ³å›ç­”ã€‚${score >= 80 ? 'æŠ€æœ¯ç†è§£æ·±å…¥ï¼Œè¡¨è¾¾æ¸…æ™°æµç•…ã€‚' : score >= 60 ? 'åŸºæœ¬æŒæ¡ç›¸å…³æ¦‚å¿µï¼Œè¡¨è¾¾æœ‰å¾…æå‡ã€‚' : 'å»ºè®®åŠ å¼ºæŠ€æœ¯å­¦ä¹ ï¼Œæé«˜è¯­éŸ³è¡¨è¾¾èƒ½åŠ›ã€‚'}`

      aiResponse = generateVoiceEnhancedResponse(analysisResult, recognizedText.value, score)
    }

    // æ›´æ–°AIæ€è€ƒè¿‡ç¨‹
    aiThinkingProcess.value = thinkingProcess

    // å»¶è¿Ÿæ˜¾ç¤ºæœ€ç»ˆå›å¤
    setTimeout(async () => {
      aiThinkingProcess.value += `

æœ€ç»ˆå›å¤ï¼š${aiResponse}`

      // ç”Ÿæˆæ™ºèƒ½æç¤º
      generateIntelligentHints(aiResponse)

      // åˆ¤æ–­æ˜¯å¦å¯ä»¥è¿›å…¥ä¸‹ä¸€é¢˜
      canProceed.value = true
      aiStatus.value = 'åˆ†æå®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€æ­¥æ“ä½œ'
      aiThinking.value = false

      // æ’­æ”¾AIå›å¤è¯­éŸ³
      try {
        await speakText(aiResponse, { rate: 0.9, pitch: 1.1 })
        ElMessage.success('AIé¢è¯•å®˜å›å¤æ’­æ”¾å®Œæˆ')
      } catch (error) {
        console.error('è¯­éŸ³æ’­æ”¾å¤±è´¥:', error)
        ElMessage.warning('è¯­éŸ³æ’­æ”¾å¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ–‡å­—å›å¤')
      }
    }, 2000)

  } catch (error) {
    console.error('AIåˆ†æå¤±è´¥:', error)
    aiThinkingProcess.value = 'åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œä½†æ‚¨çš„è¯­éŸ³å›ç­”å·²è®°å½•ã€‚è¯­éŸ³è¯†åˆ«å‡†ç¡®åº¦ï¼š' + recognitionAccuracy.value + '%'
    canProceed.value = true
    aiThinking.value = false
  }
}

// æ£€æµ‹"ä¸çŸ¥é“"ç±»å‹çš„å›ç­”
const detectUnknownAnswer = (answer) => {
  const unknownPatterns = [
    'ä¸çŸ¥é“', 'ä¸æ¸…æ¥š', 'æ²¡æœ‰ç»éªŒ', 'ä¸äº†è§£', 'ä¸ä¼š', 'æ²¡åšè¿‡',
    'ä¸å¤ªæ‡‚', 'ä¸ç¡®å®š', 'å®Œå…¨ä¸æ‡‚', 'æ²¡æœ‰æ¥è§¦è¿‡', 'ä¸å¤ªäº†è§£'
  ]

  const answerLower = answer.toLowerCase()
  const hasUnknownKeywords = unknownPatterns.some(pattern => answerLower.includes(pattern))

  // è¯­éŸ³å›ç­”é€šå¸¸è¾ƒçŸ­ï¼Œè°ƒæ•´åˆ¤æ–­æ ‡å‡†
  const isShortAnswer = answer.trim().length < 80

  return hasUnknownKeywords && (isShortAnswer || answer.trim().length < 150)
}

// ç”Ÿæˆè¯­éŸ³æ™ºèƒ½å¼•å¯¼
const generateVoiceIntelligentGuidance = async (answer, question) => {
  try {
    const guidanceContext = {
      question: question,
      candidateResponse: answer,
      domain: 'ai',
      interviewMode: 'voice',
      guidanceType: 'technical_hint'
    }

    const guidance = await enhancedIflytekSparkService.generateRealTimeHint(
      'voice_interview_guidance_' + Date.now(),
      guidanceContext
    )

    return `æ²¡å…³ç³»ï¼Œè¯šå®åœ°è¡¨è¾¾ä¸äº†è§£æ˜¯å¾ˆå¥½çš„æ€åº¦ï¼è®©æˆ‘ä¸ºæ‚¨æä¾›ä¸€äº›æ€è·¯ï¼š

ğŸ’¡ ${guidance.hint || 'å»ºè®®ä»åŸºæœ¬æ¦‚å¿µå¼€å§‹æ€è€ƒ'}

æ‚¨å¯ä»¥å°è¯•ç”¨è¯­éŸ³è¡¨è¾¾ï¼š
ğŸ¤ åŸºæœ¬æ¦‚å¿µå’Œæ‚¨çš„ç†è§£
ğŸ¤ ç›¸å…³æŠ€æœ¯å’Œå·¥å…·çš„è®¤çŸ¥
ğŸ¤ å¯èƒ½çš„åº”ç”¨åœºæ™¯
ğŸ¤ æ‚¨çš„å­¦ä¹ å…´è¶£å’Œæ–¹å‘

è¯­éŸ³é¢è¯•é‡ç‚¹è€ƒå¯Ÿæ‚¨çš„è¡¨è¾¾èƒ½åŠ›å’Œæ€ç»´é€»è¾‘ï¼Œä¸ç”¨æ‹…å¿ƒç­”æ¡ˆä¸å¤Ÿå®Œç¾ã€‚è¯·ç»§ç»­ç”¨è¯­éŸ³å›ç­”ï¼`

  } catch (error) {
    console.error('è¯­éŸ³æ™ºèƒ½å¼•å¯¼ç”Ÿæˆå¤±è´¥:', error)
    return `æ²¡å…³ç³»ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å­¦ä¹ æœºä¼šï¼

ğŸ’¡ è¿™ä¸ªé—®é¢˜æ¶‰åŠçš„æ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬æŠ€æœ¯åŸç†ã€å®ç°æ–¹æ³•å’Œåº”ç”¨åœºæ™¯ã€‚

æ‚¨å¯ä»¥å°è¯•ç”¨è¯­éŸ³è¡¨è¾¾ï¼š
ğŸ¤ å¦‚æœæ‚¨å¬è¯´è¿‡ç›¸å…³æ¦‚å¿µï¼Œå¯ä»¥åˆ†äº«æ‚¨çš„ç†è§£
ğŸ¤ å¯ä»¥è°ˆè°ˆæ‚¨è®¤ä¸ºå¯èƒ½çš„è§£å†³æ€è·¯
ğŸ¤ åˆ†äº«æ‚¨åœ¨ç›¸å…³é¢†åŸŸçš„å­¦ä¹ ç»å†
ğŸ¤ è¡¨è¾¾æ‚¨å¯¹è¿™ä¸ªæŠ€æœ¯çš„å­¦ä¹ å…´è¶£

è¯­éŸ³é¢è¯•ä¸ä»…è€ƒå¯ŸæŠ€æœ¯çŸ¥è¯†ï¼Œæ›´é‡è¦çš„æ˜¯çœ‹åˆ°æ‚¨çš„è¡¨è¾¾èƒ½åŠ›å’Œå­¦ä¹ æ€åº¦ã€‚è¯·ç»§ç»­ç”¨è¯­éŸ³å›ç­”ï¼`
  }
}

// ç”Ÿæˆè¯­éŸ³å¢å¼ºå›å¤
const generateVoiceEnhancedResponse = (analysisResult, answer, score) => {
  const hasKeywords = /ç®—æ³•|æ¨¡å‹|æ•°æ®|æŠ€æœ¯|ç³»ç»Ÿ|æ¶æ„|ä¼˜åŒ–|æ€§èƒ½/.test(answer)
  const isDetailed = answer.length > 150
  const hasTechnicalTerms = /API|æ¡†æ¶|åº“|å·¥å…·|å¹³å°|æœåŠ¡|æ¥å£/.test(answer)

  let response = ''

  if (hasKeywords && isDetailed && hasTechnicalTerms) {
    response = `å¾ˆæ£’çš„è¯­éŸ³å›ç­”ï¼æ‚¨çš„è¡¨è¾¾æ¸…æ™°æµç•…ï¼ŒæŠ€æœ¯å†…å®¹ä¹Ÿå¾ˆå‡†ç¡®ã€‚

ğŸ¤ è¯­éŸ³è¡¨è¾¾ä¼˜åŠ¿ï¼š
- é€»è¾‘æ¸…æ™°ï¼Œæ¡ç†åˆ†æ˜
- æŠ€æœ¯æœ¯è¯­ä½¿ç”¨å‡†ç¡®
- è¯­é€Ÿé€‚ä¸­ï¼Œæ˜“äºç†è§£

è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ï¼šæ‚¨åœ¨å®é™…é¡¹ç›®ä¸­æ˜¯å¦‚ä½•åº”ç”¨è¿™äº›æŠ€æœ¯çš„ï¼Ÿè¯·ç»§ç»­ç”¨è¯­éŸ³åˆ†äº«æ‚¨çš„å®è·µç»éªŒã€‚`

  } else if (hasKeywords && isDetailed) {
    response = `æ‚¨çš„è¯­éŸ³å›ç­”æœ‰ä¸€å®šçš„æŠ€æœ¯æ·±åº¦ï¼Œè¡¨è¾¾ä¹Ÿæ¯”è¾ƒæµç•…ã€‚

ğŸ¤ å»ºè®®ä¼˜åŒ–ï¼š
- å¯ä»¥è¡¥å……æ›´å¤šå…·ä½“çš„æŠ€æœ¯å®ç°ç»†èŠ‚
- å°è¯•ä½¿ç”¨æ›´å¤šä¸“ä¸šæœ¯è¯­
- å¯ä»¥åˆ†äº«å…·ä½“çš„é¡¹ç›®æ¡ˆä¾‹

èƒ½å¦ç”¨è¯­éŸ³è¯¦ç»†è¯´æ˜ä¸€ä¸‹å…·ä½“çš„æŠ€æœ¯å®ç°æ–¹æ³•ï¼Ÿ`

  } else if (hasKeywords) {
    response = `æ„Ÿè°¢æ‚¨çš„è¯­éŸ³å›ç­”ã€‚æˆ‘å¬åˆ°æ‚¨å¯¹è¿™ä¸ªé—®é¢˜æœ‰ä¸€å®šçš„ç†è§£ã€‚

ğŸ¤ è¡¨è¾¾å»ºè®®ï¼š
- å¯ä»¥æ›´è¯¦ç»†åœ°é˜è¿°æ‚¨çš„è§‚ç‚¹
- å°è¯•ä¸¾å…·ä½“çš„ä¾‹å­æ¥è¯´æ˜
- å¯ä»¥åˆ†äº«ç›¸å…³çš„å­¦ä¹ æˆ–å·¥ä½œç»éªŒ

èƒ½å¦ç”¨è¯­éŸ³ä¸¾ä¸ªå…·ä½“çš„ä¾‹å­æ¥è¿›ä¸€æ­¥è¯´æ˜ï¼Ÿ`

  } else {
    response = `æ„Ÿè°¢æ‚¨çš„è¯­éŸ³åˆ†äº«ã€‚æ‚¨å±•ç°äº†ä¸€å®šçš„æ€è€ƒè¿‡ç¨‹ã€‚

ğŸ¤ æ”¹è¿›æ–¹å‘ï¼š
- å»ºè®®ä»æŠ€æœ¯åŸç†è§’åº¦æ¥å›ç­”
- å¯ä»¥è°ˆè°ˆå®ç°æ–¹æ³•å’Œåº”ç”¨åœºæ™¯
- å°è¯•ä½¿ç”¨æ›´å¤šæŠ€æœ¯ç›¸å…³çš„è¯æ±‡

è¯·ç»§ç»­ç”¨è¯­éŸ³å®Œå–„æ‚¨çš„å›ç­”ï¼Œé‡ç‚¹å…³æ³¨æŠ€æœ¯å±‚é¢çš„å†…å®¹ã€‚`
  }

  return response
}

const generateIntelligentHints = (analysisContent) => {
  // åŸºäºAIåˆ†æç»“æœç”Ÿæˆæ™ºèƒ½æç¤º
  intelligentHints.value = [
    {
      id: 1,
      type: 'è¯­éŸ³è¡¨è¾¾',
      text: 'å»ºè®®ä¿æŒé€‚ä¸­çš„è¯­é€Ÿï¼Œæ¸…æ™°åœ°è¡¨è¾¾æŠ€æœ¯æ¦‚å¿µ'
    },
    {
      id: 2,
      type: 'å†…å®¹æ·±åº¦',
      text: 'å¯ä»¥è¿›ä¸€æ­¥è¯¦è¿°å…·ä½“çš„æŠ€æœ¯å®ç°ç»†èŠ‚'
    },
    {
      id: 3,
      type: 'å®è·µç»éªŒ',
      text: 'å»ºè®®åˆ†äº«æ›´å¤šé¡¹ç›®ä¸­çš„å®é™…åº”ç”¨ç»éªŒ'
    }
  ]
}

const confirmAnswer = () => {
  ElMessage.success('å›ç­”å·²ç¡®è®¤')
  canProceed.value = true
}

const retryRecording = () => {
  recognizedText.value = ''
  canProceed.value = false
  intelligentHints.value = []
  aiThinkingProcess.value = ''
}

const nextQuestion = () => {
  if (currentQuestion.value < totalQuestions.value) {
    currentQuestion.value++

    // æ›´æ–°é—®é¢˜å†…å®¹ï¼ˆè¿™é‡Œå¯ä»¥ä»é¢˜åº“ä¸­è·å–ï¼‰
    const questions = [
      {
        text: 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ‚¨åœ¨æœºå™¨å­¦ä¹ é¡¹ç›®ä¸­çš„ç»éªŒï¼ŒåŒ…æ‹¬æ‚¨ä½¿ç”¨è¿‡çš„ä¸»è¦æŠ€æœ¯æ ˆå’Œè§£å†³è¿‡çš„å…¸å‹é—®é¢˜ã€‚',
        difficulty: 'ä¸­ç­‰',
        hints: ['å¯ä»¥ä»å…·ä½“çš„é¡¹ç›®ç»å†å¼€å§‹', 'é‡ç‚¹æè¿°æŠ€æœ¯é€‰å‹çš„åŸå› ', 'åˆ†äº«é‡åˆ°çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ']
      },
      {
        text: 'åœ¨æ‚¨çš„é¡¹ç›®ä¸­ï¼Œå¦‚ä½•å¤„ç†æ•°æ®è´¨é‡é—®é¢˜ï¼Ÿè¯·ä¸¾ä¾‹è¯´æ˜æ‚¨ä½¿ç”¨è¿‡çš„æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†æ–¹æ³•ã€‚',
        difficulty: 'ä¸­ç­‰',
        hints: ['æè¿°å…·ä½“çš„æ•°æ®è´¨é‡é—®é¢˜', 'è¯´æ˜é‡‡ç”¨çš„æŠ€æœ¯æ–¹æ¡ˆ', 'åˆ†äº«å¤„ç†æ•ˆæœå’Œç»éªŒ']
      },
      {
        text: 'è¯·è°ˆè°ˆæ‚¨å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹ä¼˜åŒ–çš„ç†è§£ï¼ŒåŒ…æ‹¬æ‚¨åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨è¿‡çš„ä¼˜åŒ–æŠ€æœ¯ã€‚',
        difficulty: 'å›°éš¾',
        hints: ['ä»ç†è®ºåŸºç¡€å¼€å§‹', 'ç»“åˆå®é™…é¡¹ç›®ç»éªŒ', 'è¯´æ˜ä¼˜åŒ–æ•ˆæœå’ŒæŒ‡æ ‡']
      }
    ]

    if (questions[currentQuestion.value - 1]) {
      Object.assign(currentQuestionData, questions[currentQuestion.value - 1])
    }

    // é‡ç½®çŠ¶æ€
    recognizedText.value = ''
    canProceed.value = false
    intelligentHints.value = []
    aiThinkingProcess.value = ''
    aiStatus.value = 'ç­‰å¾…æ‚¨çš„å›ç­”'

  } else {
    endInterview()
  }
}

const pauseInterview = () => {
  ElMessageBox.confirm(
    'ç¡®å®šè¦æš‚åœé¢è¯•å—ï¼Ÿæ‚¨å¯ä»¥ç¨åç»§ç»­ã€‚',
    'æš‚åœé¢è¯•',
    {
      confirmButtonText: 'ç¡®å®šæš‚åœ',
      cancelButtonText: 'ç»§ç»­é¢è¯•',
      type: 'warning'
    }
  ).then(() => {
    // æš‚åœé€»è¾‘
    ElMessage.info('é¢è¯•å·²æš‚åœ')
  }).catch(() => {
    // å–æ¶ˆæš‚åœ
  })
}

const endInterview = () => {
  ElMessageBox.confirm(
    'ç¡®å®šè¦ç»“æŸé¢è¯•å—ï¼Ÿç»“æŸåå°†ç”Ÿæˆé¢è¯•æŠ¥å‘Šã€‚',
    'ç»“æŸé¢è¯•',
    {
      confirmButtonText: 'ç»“æŸé¢è¯•',
      cancelButtonText: 'ç»§ç»­é¢è¯•',
      type: 'warning'
    }
  ).then(() => {
    // æ¸…ç†èµ„æº
    if (recognition) {
      recognition.stop()
    }
    if (audioContext) {
      audioContext.close()
    }

    // è·³è½¬åˆ°ç»“æœé¡µé¢
    router.push('/interview-result')
  }).catch(() => {
    // å–æ¶ˆç»“æŸ
  })
}

const applyVoiceSettings = () => {
  // åº”ç”¨è¯­éŸ³è®¾ç½®
  if (recognition) {
    recognition.lang = recognitionLanguage.value
  }

  showVoiceSettings.value = false
  ElMessage.success('è¯­éŸ³è®¾ç½®å·²åº”ç”¨')
}

// ç”Ÿå‘½å‘¨æœŸ
onMounted(() => {
  initializeVoiceRecognition()
  initializeSpeechSynthesis()

  // å¯åŠ¨è®¡æ—¶å™¨
  const timer = setInterval(() => {
    elapsedTime.value++
  }, 1000)

  // ä¿å­˜timerå¼•ç”¨ä»¥ä¾¿æ¸…ç†
  window.interviewTimer = timer
})

onUnmounted(() => {
  // æ¸…ç†èµ„æº
  if (recognition) {
    recognition.stop()
  }
  if (audioContext) {
    audioContext.close()
  }
  if (window.interviewTimer) {
    clearInterval(window.interviewTimer)
  }
  clearTimeout(vadTimer)

  // åœæ­¢iFlytekè¯­éŸ³è¯†åˆ«
  if (iflytekRecognitionSession.value) {
    iflytekVoiceService.stopRealtimeRecognition()
  }

  // åœæ­¢è¯­éŸ³æ’­æ”¾
  stopSpeaking()
})
</script>

<style scoped>
/* ä½¿ç”¨ç®€åŒ–çš„æ ·å¼ç³»ç»Ÿ */

.voice-interview-page {
  min-height: 100vh;
  background:
    radial-gradient(circle at 30% 70%, rgba(24, 144, 255, 0.15) 0%, transparent 50%),
    radial-gradient(circle at 70% 30%, rgba(82, 196, 26, 0.1) 0%, transparent 50%),
    radial-gradient(circle at 50% 50%, rgba(250, 140, 22, 0.05) 0%, transparent 50%),
    linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
  background-attachment: fixed;
  font-family: 'Microsoft YaHei', sans-serif;
  position: relative;
}

.voice-interview-page::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background:
    url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="voicePattern" width="50" height="50" patternUnits="userSpaceOnUse"><circle cx="10" cy="10" r="1" fill="rgba(24,144,255,0.1)"/><circle cx="40" cy="40" r="0.8" fill="rgba(82,196,26,0.08)"/><circle cx="25" cy="35" r="0.6" fill="rgba(250,140,22,0.06)"/></pattern></defs><rect width="100" height="100" fill="url(%23voicePattern)"/></svg>');
  pointer-events: none;
  z-index: 0;
}

.voice-interview-header {
  background: rgba(255, 255, 255, 0.98);
  backdrop-filter: blur(25px);
  padding: 28px 32px;
  border-bottom: 1px solid rgba(24, 144, 255, 0.15);
  box-shadow:
    0 4px 32px rgba(0, 0, 0, 0.08),
    0 2px 8px rgba(0, 0, 0, 0.04);
  position: relative;
  z-index: 10;
}

.voice-interview-header::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  height: 4px;
  background: linear-gradient(90deg,
    #1890ff 0%,
    #52c41a 25%,
    #fa8c16 50%,
    #52c41a 75%,
    #1890ff 100%);
  background-size: 300% 100%;
  animation: voiceHeaderFlow 4s ease-in-out infinite;
}

@keyframes voiceHeaderFlow {
  0%, 100% { background-position: 0% 50%; }
  50% { background-position: 100% 50%; }
}

.header-content {
  max-width: 1400px;
  margin: 0 auto;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.interview-title {
  font-size: 28px;
  font-weight: 700;
  color: #1890ff;
  margin: 0 0 8px 0;
  display: flex;
  align-items: center;
  gap: 12px;
}

.title-icon {
  font-size: 24px;
}

.interview-subtitle {
  font-size: 16px;
  color: #7f8c8d;
  margin-bottom: 16px;
}

.interview-meta {
  display: flex;
  gap: 24px;
}

.meta-item {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  background: rgba(24, 144, 255, 0.05);
  border-radius: 8px;
  font-size: 14px;
  color: #2c3e50;
}

.status-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 12px 16px;
  background: rgba(255, 255, 255, 0.8);
  border-radius: 20px;
  border: 2px solid #e1e8ed;
  transition: all 0.3s ease;
}

.status-indicator.active {
  border-color: #52c41a;
  background: rgba(82, 196, 26, 0.1);
}

.status-dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background: #d9d9d9;
  transition: all 0.3s ease;
}

.status-indicator.active .status-dot {
  background: #52c41a;
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

.voice-interview-main {
  padding: 30px;
  max-width: 1400px;
  margin: 0 auto;
}

.interview-layout {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 30px;
  min-height: calc(100vh - 200px);
}

.voice-interaction-section,
.ai-interviewer-section {
  display: flex;
  flex-direction: column;
  gap: 20px;
}

.voice-visualization-card,
.voice-analysis-card,
.ai-interviewer-card,
.ai-thinking-card,
.intelligent-hints-card {
  background: rgba(255, 255, 255, 0.95);
  backdrop-filter: blur(20px);
  border-radius: 20px;
  padding: 28px;
  box-shadow:
    0 12px 40px rgba(0, 0, 0, 0.12),
    0 4px 12px rgba(0, 0, 0, 0.08),
    inset 0 1px 0 rgba(255, 255, 255, 0.8);
  border: 1px solid rgba(255, 255, 255, 0.3);
  position: relative;
  transition: all 0.3s ease;
}

.voice-visualization-card:hover,
.voice-analysis-card:hover,
.ai-interviewer-card:hover,
.ai-thinking-card:hover,
.intelligent-hints-card:hover {
  transform: translateY(-4px);
  box-shadow:
    0 16px 48px rgba(0, 0, 0, 0.15),
    0 6px 16px rgba(0, 0, 0, 0.1),
    inset 0 1px 0 rgba(255, 255, 255, 0.9);
}

.voice-visualization-card::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  border-radius: 20px;
  background: linear-gradient(135deg, rgba(24, 144, 255, 0.02) 0%, rgba(82, 196, 26, 0.02) 100%);
  pointer-events: none;
  z-index: -1;
}

/* è¯­éŸ³æŠ€æœ¯ä¼˜åŠ¿é¢æ¿ */
.voice-tech-advantages-panel {
  background: linear-gradient(135deg, rgba(82, 196, 26, 0.02) 0%, rgba(24, 144, 255, 0.02) 100%);
  border: 1px solid rgba(82, 196, 26, 0.15);
  margin-bottom: 20px;
}

.tech-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  margin-bottom: 20px;
  padding-bottom: 16px;
  border-bottom: 1px solid rgba(82, 196, 26, 0.1);
}

.tech-header h3 {
  display: flex;
  align-items: center;
  gap: 8px;
  margin: 0;
  color: #52c41a;
  font-size: 16px;
  font-weight: 600;
}

.tech-icon {
  color: #52c41a;
  font-size: 18px;
}

.voice-tech-metrics {
  display: grid;
  gap: 12px;
  margin-bottom: 20px;
}

.voice-metric-item {
  display: flex;
  align-items: center;
  gap: 12px;
  padding: 12px;
  background: rgba(255, 255, 255, 0.8);
  border-radius: 8px;
  border: 1px solid rgba(82, 196, 26, 0.1);
  transition: all 0.3s ease;
}

.voice-metric-item:hover {
  background: rgba(82, 196, 26, 0.05);
  border-color: rgba(82, 196, 26, 0.2);
}

.voice-metric-icon {
  width: 32px;
  height: 32px;
  background: linear-gradient(135deg, #52c41a 0%, #73d13d 100%);
  border-radius: 8px;
  display: flex;
  align-items: center;
  justify-content: center;
  color: white;
  font-size: 14px;
}

.voice-metric-info {
  flex: 1;
}

.voice-metric-value {
  font-size: 18px;
  font-weight: 700;
  color: #52c41a;
  line-height: 1;
}

.voice-metric-label {
  font-size: 12px;
  color: #666;
  margin-top: 2px;
}

.voice-metric-trend .trend-icon {
  font-size: 16px;
  color: #52c41a;
  transform: rotate(-45deg);
}

.voice-ai-features {
  padding-top: 16px;
  border-top: 1px solid rgba(82, 196, 26, 0.1);
}

.feature-title {
  font-size: 14px;
  font-weight: 600;
  color: #333;
  margin-bottom: 12px;
}

.feature-list {
  display: grid;
  gap: 8px;
}

.voice-feature-item {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  background: rgba(255, 255, 255, 0.6);
  border-radius: 6px;
  border: 1px solid rgba(82, 196, 26, 0.08);
  transition: all 0.3s ease;
}

.voice-feature-item.active {
  background: rgba(82, 196, 26, 0.05);
  border-color: rgba(82, 196, 26, 0.15);
}

.voice-feature-item span {
  flex: 1;
  font-size: 13px;
  color: #333;
}

.feature-status {
  margin-left: auto;
}

.voice-visual-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 20px;
}

.voice-visual-header h3 {
  color: #2c3e50;
  font-size: 18px;
  font-weight: 600;
  display: flex;
  align-items: center;
  gap: 8px;
  margin: 0;
}

.voice-quality-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
}

.quality-label {
  font-size: 12px;
  color: #7f8c8d;
}

.quality-bars {
  display: flex;
  gap: 2px;
}

.quality-bar {
  width: 4px;
  height: 16px;
  background: #e6e6e6;
  border-radius: 2px;
  transition: all 0.3s ease;
}

.quality-bar.active {
  background: #52c41a;
}

.waveform-display {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 4px;
  height: 140px;
  margin-bottom: 24px;
  padding: 24px;
  background:
    radial-gradient(circle at center, rgba(24, 144, 255, 0.05) 0%, transparent 70%),
    linear-gradient(135deg, #f8fafc 0%, #e6f7ff 100%);
  border-radius: 16px;
  border: 2px solid rgba(24, 144, 255, 0.1);
  position: relative;
  overflow: hidden;
}

.waveform-display::before {
  content: '';
  position: absolute;
  top: 0;
  left: -100%;
  width: 100%;
  height: 100%;
  background: linear-gradient(90deg,
    transparent 0%,
    rgba(24, 144, 255, 0.1) 50%,
    transparent 100%);
  animation: waveformScan 3s ease-in-out infinite;
}

@keyframes waveformScan {
  0% { left: -100%; }
  100% { left: 100%; }
}

.wave-bar {
  width: 5px;
  background: linear-gradient(180deg, #e6f7ff 0%, #bae7ff 100%);
  border-radius: 3px;
  transition: all 0.4s ease;
  position: relative;
  z-index: 2;
}

.waveform-display.active .wave-bar {
  background: linear-gradient(180deg, #1890ff 0%, #40a9ff 50%, #1890ff 100%);
  animation: wave 1.2s infinite ease-in-out;
  box-shadow: 0 0 8px rgba(24, 144, 255, 0.4);
}

@keyframes wave {
  0%, 40%, 100% { transform: scaleY(0.4); }
  20% { transform: scaleY(1); }
}

.voice-controls {
  text-align: center;
  padding: 24px;
  background: linear-gradient(135deg, rgba(24, 144, 255, 0.02) 0%, rgba(82, 196, 26, 0.02) 100%);
  border-radius: 16px;
  border: 1px solid rgba(24, 144, 255, 0.1);
}

.record-button-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 16px;
  margin-bottom: 20px;
}

.record-button {
  position: relative;
  min-width: 160px;
  height: 56px;
  border-radius: 28px;
  font-weight: 600;
  transition: all 0.3s ease;
  overflow: hidden;
}

.record-button.recording {
  animation: recordingPulse 2s infinite;
  box-shadow: 0 0 20px rgba(255, 77, 79, 0.4);
}

@keyframes recordingPulse {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.05); }
}

.recording-indicator {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 16px;
  background: rgba(255, 77, 79, 0.1);
  border-radius: 20px;
  border: 1px solid rgba(255, 77, 79, 0.2);
}

.recording-pulse {
  width: 8px;
  height: 8px;
  background: #ff4d4f;
  border-radius: 50%;
  animation: pulse 1s infinite;
}

.recording-time {
  font-weight: 600;
  color: #ff4d4f;
  font-size: 14px;
}

.voice-control-options {
  margin: 16px 0;
}

.control-hint {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
  margin: 16px 0;
  padding: 12px;
  background: rgba(24, 144, 255, 0.05);
  border-radius: 8px;
  color: #1890ff;
  font-size: 14px;
}

.voice-quality-indicator {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 12px;
  margin-top: 16px;
  padding: 12px;
  background: rgba(255, 255, 255, 0.8);
  border-radius: 12px;
  border: 1px solid rgba(24, 144, 255, 0.1);
}

.quality-label {
  font-size: 14px;
  color: #666;
  font-weight: 500;
}

.quality-bars {
  display: flex;
  gap: 3px;
}

.quality-bar {
  width: 4px;
  height: 16px;
  background: #e6e6e6;
  border-radius: 2px;
  transition: all 0.3s ease;
}

.quality-bar.active {
  background: linear-gradient(180deg, #52c41a 0%, #73d13d 100%);
  box-shadow: 0 0 4px rgba(82, 196, 26, 0.3);
}

.quality-text {
  font-size: 14px;
  font-weight: 600;
  color: #52c41a;
}

.record-button-container {
  display: flex;
  justify-content: center;
  margin-bottom: 12px;
}

.record-button {
  min-width: 140px;
  height: 50px;
  font-size: 16px;
  border-radius: 25px;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
  transition: all 0.3s ease;
  padding: 0 24px;
}

.button-text {
  white-space: nowrap;
  display: inline-block;
}

.record-button.recording {
  animation: recordPulse 1.5s infinite;
}

@keyframes recordPulse {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.05); }
}

.control-hint {
  font-size: 14px;
  color: #7f8c8d;
}

.recognition-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
}

.recognition-header h4 {
  color: #2c3e50;
  font-size: 16px;
  font-weight: 600;
  display: flex;
  align-items: center;
  gap: 8px;
  margin: 0;
}

.recognition-accuracy {
  font-size: 12px;
  color: #52c41a;
  font-weight: 600;
}

.recognized-text {
  background: #f8fafc;
  border-radius: 12px;
  border: 1px solid #e8f4fd;
  min-height: 120px;
  overflow: hidden;
}

.text-header {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 12px 16px;
  background: linear-gradient(135deg, #1890ff 0%, #0066cc 100%);
  color: white;
  font-weight: 600;
  font-size: 14px;
}

.text-header span {
  display: flex;
  align-items: center;
  gap: 6px;
}

.text-content {
  padding: 16px;
  font-size: 16px;
  line-height: 1.6;
  color: #2c3e50;
  min-height: 60px;
  background: white;
}

.text-stats {
  display: flex;
  justify-content: space-between;
  padding: 8px 16px;
  background: #f8fafc;
  border-top: 1px solid #e8f4fd;
  font-size: 12px;
  color: #666;
}

.recognition-placeholder {
  background: #f8fafc;
  border-radius: 12px;
  border: 2px dashed #d1d5db;
  min-height: 120px;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  text-align: center;
  padding: 24px;
}

.recognition-placeholder .el-icon {
  font-size: 32px;
  color: #1890ff;
  margin-bottom: 12px;
}

.recognition-placeholder p {
  margin: 4px 0;
  color: #666;
  font-size: 14px;
}

.placeholder-tip {
  color: #999 !important;
  font-size: 12px !important;
}

.voice-actions {
  margin-top: 16px;
  display: flex;
  gap: 12px;
  justify-content: center;
}

.analysis-metrics {
  display: flex;
  flex-direction: column;
  gap: 16px;
}

.metric-item {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.metric-label {
  font-size: 14px;
  color: #7f8c8d;
  font-weight: 500;
}

.metric-value {
  font-size: 16px;
  color: #2c3e50;
  font-weight: 600;
}

.metric-bar {
  height: 6px;
  background: #f0f2f5;
  border-radius: 3px;
  overflow: hidden;
}

.metric-fill {
  height: 100%;
  background: linear-gradient(90deg, #1890ff, #40a9ff);
  border-radius: 3px;
  transition: width 0.5s ease;
}

.emotion-indicator {
  width: 12px;
  height: 12px;
  border-radius: 50%;
  margin-top: 4px;
}

.emotion-indicator.ç§¯æ {
  background: #52c41a;
}

.emotion-indicator.ä¸­æ€§ {
  background: #faad14;
}

.emotion-indicator.æ¶ˆæ {
  background: #ff4d4f;
}

.interviewer-header {
  display: flex;
  align-items: center;
  gap: 16px;
  margin-bottom: 20px;
}

.interviewer-avatar {
  position: relative;
  width: 48px;
  height: 48px;
  background: linear-gradient(135deg, #1890ff, #40a9ff);
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  color: white;
  font-size: 20px;
}

.avatar-status {
  position: absolute;
  bottom: 2px;
  right: 2px;
  width: 12px;
  height: 12px;
  border-radius: 50%;
  background: #d9d9d9;
  border: 2px solid white;
  transition: all 0.3s ease;
}

.avatar-status.active {
  background: #52c41a;
}

.interviewer-info h3 {
  color: #2c3e50;
  font-size: 16px;
  font-weight: 600;
  margin: 0 0 4px 0;
}

.interviewer-info p {
  color: #7f8c8d;
  font-size: 14px;
  margin: 0;
}

.question-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
}

.question-header h4 {
  color: #2c3e50;
  font-size: 16px;
  font-weight: 600;
  display: flex;
  align-items: center;
  gap: 8px;
  margin: 0;
}

.question-content {
  background: #f8fafc;
  padding: 20px;
  border-radius: 12px;
  border-left: 4px solid #1890ff;
  font-size: 16px;
  line-height: 1.6;
  color: #2c3e50;
  margin-bottom: 16px;
}

.question-hints {
  background: rgba(250, 173, 20, 0.05);
  padding: 16px;
  border-radius: 8px;
  border-left: 4px solid #fa8c16;
}

.hints-header {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 14px;
  font-weight: 600;
  color: #fa8c16;
  margin-bottom: 12px;
}

.hints-list {
  margin: 0;
  padding-left: 20px;
}

.hints-list li {
  color: #5a6c7d;
  margin-bottom: 8px;
  font-size: 14px;
}

.thinking-header {
  display: flex;
  align-items: center;
  gap: 8px;
  font-size: 14px;
  font-weight: 600;
  color: #1890ff;
  margin-bottom: 12px;
}

.thinking-icon.rotating {
  animation: rotate 1s linear infinite;
}

@keyframes rotate {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}

.thinking-content {
  font-size: 14px;
  color: #5a6c7d;
  line-height: 1.5;
}

.thinking-steps {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.step-item {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  border-radius: 6px;
  background: #f8fafc;
  color: #999;
  transition: all 0.3s ease;
}

.step-item.active {
  background: linear-gradient(135deg, #e6f7ff 0%, #f0f9ff 100%);
  color: #1890ff;
  border-left: 3px solid #1890ff;
}

.step-item .el-icon {
  font-size: 16px;
}

.thinking-result {
  white-space: pre-line;
  background: white;
  padding: 16px;
  border-radius: 8px;
  border: 1px solid #e8f4fd;
}

.hint-item {
  display: flex;
  gap: 12px;
  margin-bottom: 12px;
}

.hint-type {
  background: #fa8c16;
  color: white;
  padding: 4px 8px;
  border-radius: 4px;
  font-size: 12px;
  font-weight: 600;
  white-space: nowrap;
}

.hint-text {
  font-size: 14px;
  color: #5a6c7d;
  line-height: 1.4;
}

.interview-controls {
  display: flex;
  gap: 12px;
  justify-content: center;
  margin-top: 20px;
}

.next-question-btn,
.pause-btn,
.end-btn {
  padding: 12px 24px;
  font-weight: 600;
  border-radius: 8px;
}

.voice-settings {
  display: flex;
  flex-direction: column;
  gap: 20px;
}

.setting-item {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.setting-item label {
  font-weight: 600;
  color: #2c3e50;
}

.setting-desc {
  font-size: 12px;
  color: #7f8c8d;
  margin-left: 8px;
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 1200px) {
  .interview-layout {
    grid-template-columns: 1fr;
    gap: 20px;
  }
}

@media (max-width: 768px) {
  .header-content {
    flex-direction: column;
    gap: 16px;
    align-items: flex-start;
  }
  
  .interview-meta {
    flex-direction: column;
    gap: 8px;
  }
  
  .voice-interview-main {
    padding: 20px;
  }
  
  .interview-controls {
    flex-direction: column;
  }
}
</style>
