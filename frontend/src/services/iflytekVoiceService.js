/**
 * iFlytekè¯­éŸ³æœåŠ¡ - å‰ç«¯é›†æˆ
 * é›†æˆiFlytek Sparkè¯­éŸ³è¯†åˆ«å’Œè¯­éŸ³åˆæˆåŠŸèƒ½
 */

class IFlytekVoiceService {
  constructor() {
    this.config = {
      baseUrl: import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000',
      endpoints: {
        asr: '/api/v1/iflytek/asr',
        tts: '/api/v1/iflytek/tts',
        voiceAnalysis: '/api/v1/iflytek/voice-analysis'
      }
    }
    
    this.isInitialized = false
    this.currentRecognitionSession = null
    this.recognitionCallbacks = new Map()
    
    console.log('ğŸ¤ iFlytekè¯­éŸ³æœåŠ¡åˆå§‹åŒ–')
  }

  /**
   * åˆå§‹åŒ–è¯­éŸ³æœåŠ¡
   */
  async initialize() {
    try {
      // æ£€æŸ¥åç«¯æœåŠ¡å¯ç”¨æ€§
      const response = await fetch(`${this.config.baseUrl}/api/v1/health`)
      if (!response.ok) {
        throw new Error('åç«¯æœåŠ¡ä¸å¯ç”¨')
      }
      
      this.isInitialized = true
      console.log('âœ… iFlytekè¯­éŸ³æœåŠ¡åˆå§‹åŒ–æˆåŠŸ')
      return true
    } catch (error) {
      console.error('âŒ iFlytekè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error)
      this.isInitialized = false
      return false
    }
  }

  /**
   * è¯­éŸ³è¯†åˆ« - å®æ—¶æµå¼è¯†åˆ«
   * @param {Blob} audioBlob - éŸ³é¢‘æ•°æ®
   * @param {Object} options - è¯†åˆ«é€‰é¡¹
   */
  async recognizeAudio(audioBlob, options = {}) {
    if (!this.isInitialized) {
      await this.initialize()
    }

    try {
      const formData = new FormData()
      formData.append('audio', audioBlob, 'audio.wav')
      formData.append('language', options.language || 'zh-CN')
      formData.append('format', options.format || 'wav')
      formData.append('sample_rate', options.sampleRate || '16000')

      const response = await fetch(`${this.config.baseUrl}${this.config.endpoints.asr}`, {
        method: 'POST',
        body: formData
      })

      if (!response.ok) {
        throw new Error(`è¯­éŸ³è¯†åˆ«è¯·æ±‚å¤±è´¥: ${response.status}`)
      }

      const result = await response.json()
      
      return {
        text: result.text || '',
        confidence: result.confidence || 0,
        segments: result.segments || [],
        duration: result.duration || 0,
        success: result.success || false
      }
    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      return {
        text: '',
        confidence: 0,
        segments: [],
        duration: 0,
        success: false,
        error: error.message
      }
    }
  }

  /**
   * å®æ—¶è¯­éŸ³è¯†åˆ« - WebSocketè¿æ¥
   * @param {Object} options - è¯†åˆ«é€‰é¡¹
   * @param {Function} onResult - ç»“æœå›è°ƒ
   * @param {Function} onError - é”™è¯¯å›è°ƒ
   */
  async startRealtimeRecognition(options = {}, onResult, onError) {
    if (!this.isInitialized) {
      await this.initialize()
    }

    try {
      // åˆ›å»ºWebSocketè¿æ¥
      const wsUrl = `${this.config.baseUrl.replace('http', 'ws')}/api/v1/iflytek/asr/realtime`
      const ws = new WebSocket(wsUrl)
      
      const sessionId = Date.now().toString()
      this.currentRecognitionSession = {
        id: sessionId,
        ws: ws,
        isActive: true
      }

      ws.onopen = () => {
        console.log('ğŸ”— å®æ—¶è¯­éŸ³è¯†åˆ«è¿æ¥å»ºç«‹')
        // å‘é€é…ç½®ä¿¡æ¯
        ws.send(JSON.stringify({
          action: 'start',
          config: {
            language: options.language || 'zh-CN',
            format: options.format || 'wav',
            sample_rate: options.sampleRate || 16000,
            enable_intermediate_result: true
          }
        }))
      }

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data)
          if (data.type === 'result' && onResult) {
            onResult({
              text: data.text || '',
              confidence: data.confidence || 0,
              isFinal: data.is_final || false,
              timestamp: data.timestamp || Date.now()
            })
          }
        } catch (error) {
          console.error('è§£æè¯†åˆ«ç»“æœå¤±è´¥:', error)
        }
      }

      ws.onerror = (error) => {
        console.error('å®æ—¶è¯­éŸ³è¯†åˆ«é”™è¯¯:', error)
        if (onError) {
          onError(error)
        }
      }

      ws.onclose = () => {
        console.log('ğŸ”Œ å®æ—¶è¯­éŸ³è¯†åˆ«è¿æ¥å…³é—­')
        this.currentRecognitionSession = null
      }

      return sessionId
    } catch (error) {
      console.error('å¯åŠ¨å®æ—¶è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      if (onError) {
        onError(error)
      }
      return null
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®åˆ°å®æ—¶è¯†åˆ«
   * @param {ArrayBuffer} audioData - éŸ³é¢‘æ•°æ®
   */
  sendAudioData(audioData) {
    if (this.currentRecognitionSession && this.currentRecognitionSession.ws.readyState === WebSocket.OPEN) {
      // å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºBase64
      const base64Audio = this.arrayBufferToBase64(audioData)
      this.currentRecognitionSession.ws.send(JSON.stringify({
        action: 'audio',
        data: base64Audio
      }))
    }
  }

  /**
   * åœæ­¢å®æ—¶è¯­éŸ³è¯†åˆ«
   */
  stopRealtimeRecognition() {
    if (this.currentRecognitionSession) {
      this.currentRecognitionSession.ws.send(JSON.stringify({
        action: 'stop'
      }))
      this.currentRecognitionSession.ws.close()
      this.currentRecognitionSession = null
    }
  }

  /**
   * è¯­éŸ³åˆæˆ
   * @param {string} text - è¦åˆæˆçš„æ–‡æœ¬
   * @param {Object} options - åˆæˆé€‰é¡¹
   */
  async synthesizeText(text, options = {}) {
    if (!this.isInitialized) {
      await this.initialize()
    }

    try {
      const response = await fetch(`${this.config.baseUrl}${this.config.endpoints.tts}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text: text,
          voice: options.voice || 'xiaoyan',
          speed: options.speed || 50,
          volume: options.volume || 50,
          pitch: options.pitch || 50,
          format: options.format || 'wav'
        })
      })

      if (!response.ok) {
        throw new Error(`è¯­éŸ³åˆæˆè¯·æ±‚å¤±è´¥: ${response.status}`)
      }

      const audioBlob = await response.blob()
      return {
        audio: audioBlob,
        success: true
      }
    } catch (error) {
      console.error('è¯­éŸ³åˆæˆå¤±è´¥:', error)
      return {
        audio: null,
        success: false,
        error: error.message
      }
    }
  }

  /**
   * è¯­éŸ³è´¨é‡åˆ†æ
   * @param {Blob} audioBlob - éŸ³é¢‘æ•°æ®
   */
  async analyzeVoiceQuality(audioBlob) {
    if (!this.isInitialized) {
      await this.initialize()
    }

    try {
      const formData = new FormData()
      formData.append('audio', audioBlob, 'audio.wav')

      const response = await fetch(`${this.config.baseUrl}${this.config.endpoints.voiceAnalysis}`, {
        method: 'POST',
        body: formData
      })

      if (!response.ok) {
        throw new Error(`è¯­éŸ³åˆ†æè¯·æ±‚å¤±è´¥: ${response.status}`)
      }

      const result = await response.json()
      
      return {
        quality_score: result.quality_score || 0,
        clarity: result.clarity || 0,
        fluency: result.fluency || 0,
        pronunciation: result.pronunciation || 0,
        emotion: result.emotion || 'neutral',
        speech_rate: result.speech_rate || 0,
        volume_level: result.volume_level || 0,
        success: result.success || false
      }
    } catch (error) {
      console.error('è¯­éŸ³è´¨é‡åˆ†æå¤±è´¥:', error)
      return {
        quality_score: 0,
        clarity: 0,
        fluency: 0,
        pronunciation: 0,
        emotion: 'neutral',
        speech_rate: 0,
        volume_level: 0,
        success: false,
        error: error.message
      }
    }
  }

  /**
   * å·¥å…·æ–¹æ³•ï¼šArrayBufferè½¬Base64
   */
  arrayBufferToBase64(buffer) {
    let binary = ''
    const bytes = new Uint8Array(buffer)
    const len = bytes.byteLength
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i])
    }
    return window.btoa(binary)
  }

  /**
   * æ£€æŸ¥æœåŠ¡çŠ¶æ€
   */
  isServiceAvailable() {
    return this.isInitialized
  }

  /**
   * è·å–æ”¯æŒçš„è¯­éŸ³åˆ—è¡¨
   */
  async getSupportedVoices() {
    try {
      const response = await fetch(`${this.config.baseUrl}/api/v1/iflytek/voices`)
      if (response.ok) {
        const data = await response.json()
        return data.voices || []
      }
    } catch (error) {
      console.error('è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥:', error)
    }
    return []
  }
}

// åˆ›å»ºå•ä¾‹å®ä¾‹
const iflytekVoiceService = new IFlytekVoiceService()

export default iflytekVoiceService
